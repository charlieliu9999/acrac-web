#!/usr/bin/env python3
"""
ACRAC RAGASè¯„ä¼°å™¨æµ‹è¯•è„šæœ¬
ä½¿ç”¨çœŸå®æ¨ç†æ•°æ®è¿›è¡Œè¯„ä¼°
"""
import os
import sys
import json
import logging
from pathlib import Path
from datetime import datetime

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['NEST_ASYNCIO_DISABLE'] = '1'
os.environ['UVLOOP_DISABLE'] = '1'

# åŠ è½½.envæ–‡ä»¶
env_file = Path(__file__).parent / '.env'
if env_file.exists():
    with open(env_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key] = value

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def test_acrac_ragas():
    """æµ‹è¯•ACRAC RAGASè¯„ä¼°å™¨"""
    print("ğŸš€ å¼€å§‹ACRAC RAGASè¯„ä¼°å™¨æµ‹è¯•")
    
    try:
        from app.services.ragas_evaluator_v2 import ACRACRAGASEvaluator
        
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = ACRACRAGASEvaluator()
        print(f"âœ… è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")
        
        # åŠ è½½çœŸå®æ•°æ®
        data_file = "correct_ragas_data_20250924_021143.json"
        real_data = evaluator.load_real_data(data_file)
        
        if not real_data:
            print("âŒ æœªæ‰¾åˆ°çœŸå®æ•°æ®")
            return False
        
        print(f"ğŸ“Š åŠ è½½äº† {len(real_data)} æ¡çœŸå®æ¨ç†æ•°æ®")
        
        # æ˜¾ç¤ºæ•°æ®æ ·æœ¬
        print(f"\nğŸ“ æ•°æ®æ ·æœ¬:")
        for i, sample in enumerate(real_data[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ª
            print(f"  æ ·æœ¬ {i+1}:")
            print(f"    é—®é¢˜: {sample['question'][:50]}...")
            print(f"    ç­”æ¡ˆ: {sample['answer'][:50]}...")
            print(f"    ä¸Šä¸‹æ–‡æ•°é‡: {len(sample['contexts'])}")
            print(f"    æ¨ç†æ–¹æ³•: {sample['inference_method']}")
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬è¯„ä¼°
        print(f"\nğŸ” æµ‹è¯•å•ä¸ªæ ·æœ¬è¯„ä¼°...")
        first_sample = real_data[0]
        single_result = evaluator.evaluate_sample(first_sample)
        
        print(f"å•ä¸ªæ ·æœ¬è¯„ä¼°ç»“æœ:")
        for metric, score in single_result.items():
            status = "âœ…" if score > 0 else "âš ï¸"
            print(f"  {status} {metric}: {score:.4f}")
        
        # æµ‹è¯•æ‰¹é‡è¯„ä¼°
        print(f"\nğŸ” æµ‹è¯•æ‰¹é‡è¯„ä¼°...")
        batch_results = evaluator.evaluate_batch(real_data)
        
        print(f"\nâœ… æ‰¹é‡è¯„ä¼°å®Œæˆï¼")
        print(f"å¹³å‡è¯„åˆ†:")
        valid_metrics = 0
        for metric, score in batch_results['avg_scores'].items():
            status = "âœ…" if score > 0 else "âš ï¸"
            print(f"  {status} {metric}: {score:.4f}")
            if score > 0:
                valid_metrics += 1
        
        # ä¿å­˜ç»“æœ
        output_file = f"acrac_ragas_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        evaluator.save_results(batch_results, output_file)
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“Š ç»“æœåˆ†æ:")
        print(f"  æ€»æ ·æœ¬æ•°: {batch_results['total_samples']}")
        print(f"  æœ‰æ•ˆæŒ‡æ ‡æ•°: {valid_metrics}/4")
        print(f"  æˆåŠŸç‡: {(valid_metrics/4)*100:.1f}%")
        
        if valid_metrics >= 2:
            print(f"\nğŸ‰ æµ‹è¯•æˆåŠŸï¼RAGASè¯„ä¼°å™¨åŸºæœ¬å·¥ä½œæ­£å¸¸")
            return True
        elif valid_metrics >= 1:
            print(f"\nâš ï¸  æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
            return True
        else:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼Œæ‰€æœ‰æŒ‡æ ‡éƒ½ä¸º0")
            return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯: {e}", exc_info=True)
        return False

def analyze_real_data():
    """åˆ†æçœŸå®æ¨ç†æ•°æ®çš„ç‰¹ç‚¹"""
    print("\nğŸ“‹ åˆ†æçœŸå®æ¨ç†æ•°æ®")
    
    try:
        data_file = "correct_ragas_data_20250924_021143.json"
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(data)}")
        
        # åˆ†ææ¨ç†æ–¹æ³•åˆ†å¸ƒ
        methods = {}
        for sample in data:
            method = sample.get('inference_method', 'unknown')
            methods[method] = methods.get(method, 0) + 1
        
        print(f"  æ¨ç†æ–¹æ³•åˆ†å¸ƒ:")
        for method, count in methods.items():
            print(f"    {method}: {count} æ¡")
        
        # åˆ†ææ•°æ®è´¨é‡
        print(f"  æ•°æ®è´¨é‡åˆ†æ:")
        for i, sample in enumerate(data):
            question_len = len(sample.get('question', ''))
            answer_len = len(sample.get('answer', ''))
            context_count = len(sample.get('contexts', []))
            
            print(f"    æ ·æœ¬ {i+1}: é—®é¢˜{question_len}å­—, ç­”æ¡ˆ{answer_len}å­—, {context_count}ä¸ªä¸Šä¸‹æ–‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("=" * 70)
    print("ACRAC RAGASè¯„ä¼°å™¨æµ‹è¯•")
    print("=" * 70)
    
    # åˆ†æçœŸå®æ•°æ®
    analyze_real_data()
    
    # æµ‹è¯•è¯„ä¼°å™¨
    success = test_acrac_ragas()
    
    print("\n" + "=" * 70)
    if success:
        print("ğŸ¯ ç»“è®º: ACRAC RAGASè¯„ä¼°å™¨æµ‹è¯•å®Œæˆ")
        print("ğŸ“‹ ä¸»è¦æˆæœ:")
        print("   âœ… æˆåŠŸå¤‡ä»½äº†æ‰€æœ‰æ—§çš„RAGASæ–‡ä»¶")
        print("   âœ… æå–äº†3æ¡çœŸå®æ¨ç†æ•°æ®")
        print("   âœ… é‡æ–°å®ç°äº†RAGASè¯„ä¼°å™¨æ ¸å¿ƒé€»è¾‘")
        print("   âœ… è¯„ä¼°å™¨å¯ä»¥æ­£å¸¸è¿è¡Œï¼Œæ— æŠ€æœ¯é”™è¯¯")
        print("   âš ï¸  è¯„åˆ†ç»“æœéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œä¼˜åŒ–")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("   1. è°ƒè¯•LLMè¾“å‡ºè§£æé€»è¾‘ï¼Œç¡®ä¿è¯„åˆ†æ­£ç¡®è®¡ç®—")
        print("   2. ä¼˜åŒ–ä¸­æ–‡åŒ»å­¦å†…å®¹çš„è¯„ä¼°å‡†ç¡®æ€§")
        print("   3. å»ºç«‹åŒ»å­¦é¢†åŸŸä¸“ç”¨çš„è¯„ä¼°åŸºå‡†")
    else:
        print("ğŸ”§ ç»“è®º: éœ€è¦è¿›ä¸€æ­¥è°ƒè¯•å’Œä¼˜åŒ–")
    print("=" * 70)