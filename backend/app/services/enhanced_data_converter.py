#!/usr/bin/env python3
"""
æ¨ç†æ•°æ®è½¬æ¢å™¨
ä¸“é—¨ä»æ¨ç†æ•°æ®ä¸­æå–æ£€æŸ¥é¡¹ç›®æ¨èç›¸å…³çš„è¯„æµ‹è¾“å…¥æ•°æ®
å¿ äºåŸå§‹æ•°æ®ï¼Œä¸è¿›è¡Œé¢å¤–å¤„ç†
"""
import json
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod
from datetime import datetime

try:
    from ragas.dataset_schema import SingleTurnSample
    RAGAS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"RAGASç›¸å…³ä¾èµ–æœªå®‰è£…: {e}")
    RAGAS_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class ConversionResult:
    """è½¬æ¢ç»“æœ"""
    success: bool
    sample: Optional[SingleTurnSample] = None
    error_message: Optional[str] = None
    processing_info: Dict[str, Any] = None
    medical_terms: List[str] = None
    chinese_processing: Dict[str, Any] = None


@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    is_valid: bool
    errors: List[str] = None
    warnings: List[str] = None
    suggestions: List[str] = None


class BaseDataConverter(ABC):
    """æ•°æ®è½¬æ¢å™¨åŸºç±»"""
    
    @abstractmethod
    async def convert_rag_result(self, rag_result: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢ RAG æ¨ç†ç»“æœ"""
        pass
    
    @abstractmethod
    async def convert_excel_data(self, excel_data: List[Dict[str, Any]]) -> List[ConversionResult]:
        """è½¬æ¢ Excel æ•°æ®"""
        pass
    
    @abstractmethod
    async def validate_sample(self, sample: SingleTurnSample) -> ValidationResult:
        """éªŒè¯æ ·æœ¬æ•°æ®"""
        pass


class EnhancedDataConverter(BaseDataConverter):
    """å¢å¼ºç‰ˆæ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self, medical_domain: bool = True, chinese_optimization: bool = True):
        self.medical_domain = medical_domain
        self.chinese_optimization = chinese_optimization
        
        # åˆå§‹åŒ–ä¸­æ–‡åˆ†è¯
        if chinese_optimization:
            self._init_chinese_processing()
        
        # åŒ»å­¦æœ¯è¯­è¯å…¸
        if medical_domain:
            self._init_medical_terms()
    
    def _init_chinese_processing(self):
        """åˆå§‹åŒ–ä¸­æ–‡å¤„ç†"""
        try:
            # åŠ è½½è‡ªå®šä¹‰è¯å…¸
            jieba.load_userdict(self._get_medical_dict_path())
            logger.info("ä¸­æ–‡å¤„ç†åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.warning(f"ä¸­æ–‡å¤„ç†åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def _init_medical_terms(self):
        """åˆå§‹åŒ–åŒ»å­¦æœ¯è¯­è¯å…¸"""
        self.medical_keywords = {
            # ç–¾ç—…ç›¸å…³
            'diseases': ['ç³–å°¿ç—…', 'é«˜è¡€å‹', 'å¿ƒè„ç—…', 'ç™Œç—‡', 'è‚¿ç˜¤', 'è‚ºç‚', 'è‚ç‚', 'è‚¾ç‚', 'èƒƒç‚', 'è‚ ç‚'],
            # ç—‡çŠ¶ç›¸å…³
            'symptoms': ['ç–¼ç—›', 'å‘çƒ­', 'å’³å—½', 'å¤´ç—›', 'å¤´æ™•', 'æ¶å¿ƒ', 'å‘•å', 'è…¹æ³»', 'ä¾¿ç§˜', 'å¤±çœ '],
            # æ²»ç–—ç›¸å…³
            'treatments': ['æ‰‹æœ¯', 'åŒ–ç–—', 'æ”¾ç–—', 'è¯ç‰©æ²»ç–—', 'ç‰©ç†æ²»ç–—', 'åº·å¤è®­ç»ƒ', 'é¥®é£Ÿæ§åˆ¶'],
            # æ£€æŸ¥ç›¸å…³
            'examinations': ['CT', 'MRI', 'Xå…‰', 'Bè¶…', 'å¿ƒç”µå›¾', 'è¡€å¸¸è§„', 'å°¿å¸¸è§„', 'ç”ŸåŒ–æ£€æŸ¥'],
            # è¯ç‰©ç›¸å…³
            'medications': ['æŠ—ç”Ÿç´ ', 'æ­¢ç—›è¯', 'é™å‹è¯', 'é™ç³–è¯', 'ç»´ç”Ÿç´ ', 'é’™ç‰‡', 'å¶é…¸']
        }
        
        # åˆå¹¶æ‰€æœ‰å…³é”®è¯
        self.all_medical_terms = []
        for category, terms in self.medical_keywords.items():
            self.all_medical_terms.extend(terms)
        
        logger.info(f"åŒ»å­¦æœ¯è¯­è¯å…¸åˆå§‹åŒ–å®Œæˆï¼Œå…± {len(self.all_medical_terms)} ä¸ªæœ¯è¯­")
    
    def _get_medical_dict_path(self) -> str:
        """è·å–åŒ»å­¦è¯å…¸è·¯å¾„"""
        # è¿™é‡Œå¯ä»¥è¿”å›è‡ªå®šä¹‰åŒ»å­¦è¯å…¸çš„è·¯å¾„
        return ""
    
    async def convert_rag_result(self, rag_result: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢ RAG æ¨ç†ç»“æœ"""
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            question = self._extract_question(rag_result)
            answer = self._extract_answer(rag_result)
            contexts = self._extract_contexts(rag_result)
            ground_truth = self._extract_ground_truth(rag_result)
            
            # ä¸­æ–‡é¢„å¤„ç†
            if self.chinese_optimization:
                question = await self.preprocess_chinese_content(question)
                answer = await self.preprocess_chinese_content(answer)
                contexts = [await self.preprocess_chinese_content(ctx) for ctx in contexts]
                if ground_truth:
                    ground_truth = await self.preprocess_chinese_content(ground_truth)
            
            # åŒ»å­¦æœ¯è¯­æå–
            medical_terms = []
            if self.medical_domain:
                medical_terms.extend(await self.extract_medical_terms(question))
                medical_terms.extend(await self.extract_medical_terms(answer))
                for ctx in contexts:
                    medical_terms.extend(await self.extract_medical_terms(ctx))
            
            # ä¸Šä¸‹æ–‡æ™ºèƒ½è¿‡æ»¤
            contexts = await self.normalize_contexts(contexts)
            
            # åˆ›å»º RAGAS æ ·æœ¬
            sample = SingleTurnSample(
                user_input=question,
                response=answer,
                retrieved_contexts=contexts,
                reference=ground_truth
            )
            
            # éªŒè¯æ ·æœ¬
            validation = await self.validate_sample(sample)
            
            # æ”¶é›†å¤„ç†ä¿¡æ¯
            processing_info = {
                'original_rag_result': rag_result,
                'medical_terms_found': len(set(medical_terms)),
                'contexts_filtered': len(contexts),
                'chinese_processing_applied': self.chinese_optimization,
                'medical_domain_processing': self.medical_domain
            }
            
            chinese_processing = {
                'is_chinese_content': any('\u4e00' <= char <= '\u9fff' for char in question + answer),
                'chinese_character_count': sum(1 for char in question + answer if '\u4e00' <= char <= '\u9fff'),
                'processing_method': 'enhanced_chinese_processing' if self.chinese_optimization else 'standard'
            }
            
            return ConversionResult(
                success=validation.is_valid,
                sample=sample if validation.is_valid else None,
                error_message=None if validation.is_valid else '; '.join(validation.errors),
                processing_info=processing_info,
                medical_terms=list(set(medical_terms)),
                chinese_processing=chinese_processing
            )
            
        except Exception as e:
            logger.error(f"RAG ç»“æœè½¬æ¢å¤±è´¥: {e}")
            return ConversionResult(
                success=False,
                error_message=str(e),
                processing_info={'error': str(e)},
                medical_terms=[],
                chinese_processing={}
            )
    
    def _extract_question(self, rag_result: Dict[str, Any]) -> str:
        """æå–é—®é¢˜"""
        return str(rag_result.get('question', rag_result.get('query', rag_result.get('user_input', ''))))
    
    def _extract_answer(self, rag_result: Dict[str, Any]) -> str:
        """æå–ç­”æ¡ˆ"""
        answer = rag_result.get('answer', rag_result.get('response', rag_result.get('result', '')))
        
        # å¦‚æœç­”æ¡ˆæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
        if isinstance(answer, dict):
            answer = answer.get('text', answer.get('content', str(answer)))
        
        return str(answer)
    
    def _extract_contexts(self, rag_result: Dict[str, Any]) -> List[str]:
        """æå–ä¸Šä¸‹æ–‡"""
        contexts = rag_result.get('contexts', rag_result.get('retrieved_contexts', rag_result.get('context', [])))
        
        if isinstance(contexts, str):
            contexts = [contexts]
        elif not isinstance(contexts, list):
            contexts = [str(contexts)]
        
        return [str(ctx) for ctx in contexts if ctx and str(ctx).strip()]
    
    def _extract_ground_truth(self, rag_result: Dict[str, Any]) -> str:
        """æå–æ ‡å‡†ç­”æ¡ˆ"""
        return str(rag_result.get('ground_truth', rag_result.get('reference', rag_result.get('expected_answer', ''))))
    
    async def convert_excel_data(self, excel_data: List[Dict[str, Any]]) -> List[ConversionResult]:
        """è½¬æ¢ Excel æ•°æ®"""
        results = []
        
        for i, row_data in enumerate(excel_data):
            try:
                # æ ‡å‡†åŒ– Excel æ•°æ®æ ¼å¼
                standardized_data = self._standardize_excel_row(row_data)
                
                # è½¬æ¢å•ä¸ªæ ·æœ¬
                result = await self.convert_rag_result(standardized_data)
                results.append(result)
                
                logger.debug(f"Excel è¡Œ {i+1} è½¬æ¢å®Œæˆ")
                
            except Exception as e:
                logger.error(f"Excel è¡Œ {i+1} è½¬æ¢å¤±è´¥: {e}")
                results.append(ConversionResult(
                    success=False,
                    error_message=f"è¡Œ {i+1} è½¬æ¢å¤±è´¥: {str(e)}",
                    processing_info={'row_index': i, 'error': str(e)},
                    medical_terms=[],
                    chinese_processing={}
                ))
        
        return results
    
    def _standardize_excel_row(self, row_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ‡å‡†åŒ– Excel è¡Œæ•°æ®"""
        # å¸¸è§çš„ Excel åˆ—åæ˜ å°„
        column_mapping = {
            'clinical_query': 'question',
            'question': 'question',
            'query': 'question',
            'user_input': 'question',
            'answer': 'answer',
            'response': 'answer',
            'result': 'answer',
            'ground_truth': 'ground_truth',
            'reference': 'ground_truth',
            'expected_answer': 'ground_truth',
            'contexts': 'contexts',
            'retrieved_contexts': 'contexts',
            'context': 'contexts'
        }
        
        standardized = {}
        for excel_key, standard_key in column_mapping.items():
            if excel_key in row_data:
                standardized[standard_key] = row_data[excel_key]
        
        # æ·»åŠ è¡Œç´¢å¼•ä½œä¸º ID
        if 'id' not in standardized:
            standardized['id'] = f"excel_row_{hash(str(row_data))}"
        
        return standardized
    
    async def validate_sample(self, sample: SingleTurnSample) -> ValidationResult:
        """éªŒè¯æ ·æœ¬æ•°æ®"""
        errors = []
        warnings = []
        suggestions = []
        
        # éªŒè¯é—®é¢˜
        if not sample.user_input or not sample.user_input.strip():
            errors.append("é—®é¢˜ä¸èƒ½ä¸ºç©º")
        elif len(sample.user_input.strip()) < 3:
            warnings.append("é—®é¢˜è¿‡çŸ­ï¼Œå¯èƒ½å½±å“è¯„æµ‹è´¨é‡")
        
        # éªŒè¯ç­”æ¡ˆ
        if not sample.response or not sample.response.strip():
            errors.append("ç­”æ¡ˆä¸èƒ½ä¸ºç©º")
        elif len(sample.response.strip()) < 5:
            warnings.append("ç­”æ¡ˆè¿‡çŸ­ï¼Œå¯èƒ½å½±å“è¯„æµ‹è´¨é‡")
        
        # éªŒè¯ä¸Šä¸‹æ–‡
        if not sample.retrieved_contexts:
            warnings.append("æ²¡æœ‰æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡")
        else:
            # æ£€æŸ¥ä¸Šä¸‹æ–‡è´¨é‡
            for i, ctx in enumerate(sample.retrieved_contexts):
                if not ctx or not ctx.strip():
                    warnings.append(f"ä¸Šä¸‹æ–‡ {i+1} ä¸ºç©º")
                elif len(ctx.strip()) < 10:
                    warnings.append(f"ä¸Šä¸‹æ–‡ {i+1} è¿‡çŸ­")
                elif len(ctx.strip()) > 1000:
                    warnings.append(f"ä¸Šä¸‹æ–‡ {i+1} è¿‡é•¿ï¼Œå¯èƒ½å½±å“å¤„ç†æ•ˆç‡")
        
        # éªŒè¯æ ‡å‡†ç­”æ¡ˆ
        if sample.reference and len(sample.reference.strip()) < 5:
            warnings.append("æ ‡å‡†ç­”æ¡ˆè¿‡çŸ­")
        
        # ä¸­æ–‡å†…å®¹æ£€æŸ¥
        if self.chinese_optimization:
            chinese_chars = sum(1 for char in sample.user_input + sample.response if '\u4e00' <= char <= '\u9fff')
            if chinese_chars > 0 and chinese_chars < 5:
                suggestions.append("æ£€æµ‹åˆ°ä¸­æ–‡å†…å®¹ï¼Œå»ºè®®ä½¿ç”¨ä¸­æ–‡ä¼˜åŒ–å¤„ç†")
        
        # åŒ»å­¦å†…å®¹æ£€æŸ¥
        if self.medical_domain:
            medical_terms_found = await self.extract_medical_terms(sample.user_input + sample.response)
            if medical_terms_found:
                suggestions.append(f"æ£€æµ‹åˆ°åŒ»å­¦æœ¯è¯­: {', '.join(medical_terms_found[:3])}")
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings,
            suggestions=suggestions
        )
    
    async def preprocess_chinese_content(self, content: str) -> str:
        """é¢„å¤„ç†ä¸­æ–‡å†…å®¹"""
        if not content or not self.chinese_optimization:
            return content
        
        try:
            # æ¸…ç†æ–‡æœ¬
            content = content.strip()
            
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            content = re.sub(r'\s+', ' ', content)
            
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ä½†ä¿ç•™ä¸­æ–‡æ ‡ç‚¹
            content = re.sub(r'[^\u4e00-\u9fff\w\sï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹]', '', content)
            
            # æ ‡å‡†åŒ–ä¸­æ–‡æ ‡ç‚¹
            content = content.replace('ï¼Œ', 'ï¼Œ').replace('ã€‚', 'ã€‚')
            content = content.replace('ï¼', 'ï¼').replace('ï¼Ÿ', 'ï¼Ÿ')
            
            return content
            
        except Exception as e:
            logger.warning(f"ä¸­æ–‡å†…å®¹é¢„å¤„ç†å¤±è´¥: {e}")
            return content
    
    async def extract_medical_terms(self, text: str) -> List[str]:
        """æå–åŒ»å­¦æœ¯è¯­"""
        if not text or not self.medical_domain:
            return []
        
        try:
            medical_terms = []
            
            # åŸºäºè¯å…¸çš„æœ¯è¯­æå–
            for term in self.all_medical_terms:
                if term in text:
                    medical_terms.append(term)
            
            # ä½¿ç”¨åˆ†è¯æå–å¯èƒ½çš„åŒ»å­¦æœ¯è¯­
            if self.chinese_optimization:
                try:
                    words = jieba.lcut(text)
                    for word in words:
                        if len(word) >= 2 and any(char in word for char in 'ç—…ç—›ç—‡æ²»è¯æ£€'):
                            medical_terms.append(word)
                except AttributeError:
                    # å¦‚æœ jieba.lcut ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
                    for term in ['ç—…', 'ç—›', 'ç—‡', 'æ²»', 'è¯', 'æ£€']:
                        if term in text:
                            medical_terms.append(term)
            
            return list(set(medical_terms))
            
        except Exception as e:
            logger.warning(f"åŒ»å­¦æœ¯è¯­æå–å¤±è´¥: {e}")
            return []
    
    async def normalize_contexts(self, contexts: List[str]) -> List[str]:
        """æ ‡å‡†åŒ–ä¸Šä¸‹æ–‡"""
        if not contexts:
            return ["ç›¸å…³åŒ»å­¦çŸ¥è¯†"]  # é»˜è®¤ä¸Šä¸‹æ–‡
        
        normalized = []
        seen = set()
        
        for ctx in contexts:
            if not ctx or not ctx.strip():
                continue
            
            # æ¸…ç†ä¸Šä¸‹æ–‡
            ctx = ctx.strip()
            
            # å»é‡
            if ctx in seen:
                continue
            
            # é•¿åº¦é™åˆ¶
            if len(ctx) > 500:
                ctx = ctx[:500] + "..."
            
            # è´¨é‡æ£€æŸ¥
            if len(ctx) < 10:
                continue
            
            normalized.append(ctx)
            seen.add(ctx)
        
        # é™åˆ¶ä¸Šä¸‹æ–‡æ•°é‡
        if len(normalized) > 5:
            normalized = normalized[:5]
        
        return normalized if normalized else ["ç›¸å…³åŒ»å­¦çŸ¥è¯†"]
    
    async def create_enhanced_sample(self, data: Dict[str, Any]) -> SingleTurnSample:
        """åˆ›å»ºå¢å¼ºç‰ˆæ ·æœ¬"""
        result = await self.convert_rag_result(data)
        
        if not result.success:
            raise ValueError(f"æ•°æ®è½¬æ¢å¤±è´¥: {result.error_message}")
        
        return result.sample
    
    async def batch_convert(self, data_list: List[Dict[str, Any]]) -> Tuple[List[SingleTurnSample], List[str]]:
        """æ‰¹é‡è½¬æ¢æ•°æ®"""
        samples = []
        errors = []
        
        for i, data in enumerate(data_list):
            try:
                result = await self.convert_rag_result(data)
                if result.success:
                    samples.append(result.sample)
                else:
                    errors.append(f"æ ·æœ¬ {i+1}: {result.error_message}")
            except Exception as e:
                errors.append(f"æ ·æœ¬ {i+1}: {str(e)}")
        
        return samples, errors


# å…¼å®¹æ€§å‡½æ•°
def create_enhanced_data_converter(medical_domain: bool = True, 
                                 chinese_optimization: bool = True) -> EnhancedDataConverter:
    """åˆ›å»ºå¢å¼ºç‰ˆæ•°æ®è½¬æ¢å™¨å®ä¾‹"""
    return EnhancedDataConverter(medical_domain, chinese_optimization)


if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºç‰ˆæ•°æ®è½¬æ¢å™¨
    print("ğŸš€ æµ‹è¯•å¢å¼ºç‰ˆæ•°æ®è½¬æ¢å™¨")
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    async def test_converter():
        try:
            # åˆ›å»ºè½¬æ¢å™¨
            converter = create_enhanced_data_converter()
            print("âœ… å¢å¼ºç‰ˆæ•°æ®è½¬æ¢å™¨åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•æ•°æ®
            test_data = {
                "id": "test_001",
                "question": "ç³–å°¿ç—…æ‚£è€…çš„é¥®é£Ÿç®¡ç†å»ºè®®ï¼Ÿ",
                "answer": "ç³–å°¿ç—…æ‚£è€…é¥®é£Ÿç®¡ç†ï¼š1. æ§åˆ¶æ€»çƒ­é‡ 2. åˆç†åˆ†é…ä¸‰å¤§è¥å…»ç´  3. å®šæ—¶å®šé‡è¿›é¤",
                "contexts": [
                    "ç³–å°¿ç—…éœ€è¦ä¸¥æ ¼çš„é¥®é£Ÿæ§åˆ¶",
                    "è¥å…»å‡è¡¡å¯¹è¡€ç³–æ§åˆ¶å¾ˆé‡è¦"
                ],
                "ground_truth": "ç³–å°¿ç—…æ‚£è€…åº”è¯¥æ§åˆ¶é¥®é£Ÿ"
            }
            
            # è½¬æ¢æ•°æ®
            result = await converter.convert_rag_result(test_data)
            
            if result.success:
                print("âœ… æ•°æ®è½¬æ¢æˆåŠŸ")
                print(f"   åŒ»å­¦æœ¯è¯­: {result.medical_terms}")
                print(f"   ä¸­æ–‡å¤„ç†: {result.chinese_processing}")
                print(f"   å¤„ç†ä¿¡æ¯: {result.processing_info}")
                
                # éªŒè¯æ ·æœ¬
                validation = await converter.validate_sample(result.sample)
                print(f"   éªŒè¯ç»“æœ: {'é€šè¿‡' if validation.is_valid else 'å¤±è´¥'}")
                if validation.warnings:
                    print(f"   è­¦å‘Š: {validation.warnings}")
                if validation.suggestions:
                    print(f"   å»ºè®®: {validation.suggestions}")
            else:
                print(f"âŒ æ•°æ®è½¬æ¢å¤±è´¥: {result.error_message}")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    asyncio.run(test_converter())
