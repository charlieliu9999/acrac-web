#!/usr/bin/env python3
"""
æ¨ç†æ•°æ®è½¬æ¢å™¨
ä¸“é—¨ä»æ¨ç†æ•°æ®ä¸­æå–æ£€æŸ¥é¡¹ç›®æ¨èç›¸å…³çš„è¯„æµ‹è¾“å…¥æ•°æ®
å¿ äºåŸå§‹æ•°æ®ï¼Œä¸è¿›è¡Œé¢å¤–å¤„ç†
"""
import json
import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod
from datetime import datetime

try:
    from ragas.dataset_schema import SingleTurnSample
    RAGAS_AVAILABLE = True
except ImportError as e:
    logging.warning(f"RAGASç›¸å…³ä¾èµ–æœªå®‰è£…: {e}")
    RAGAS_AVAILABLE = False

logger = logging.getLogger(__name__)


@dataclass
class ConversionResult:
    """è½¬æ¢ç»“æœ"""
    success: bool
    sample: Optional[SingleTurnSample] = None
    error_message: Optional[str] = None
    extracted_fields: Dict[str, Any] = None
    processing_info: Dict[str, Any] = None


@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    is_valid: bool
    errors: List[str] = None
    warnings: List[str] = None


class BaseInferenceDataConverter(ABC):
    """æ¨ç†æ•°æ®è½¬æ¢å™¨åŸºç±»"""
    
    @abstractmethod
    async def convert_inference_data(self, inference_data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢æ¨ç†æ•°æ®"""
        pass
    
    @abstractmethod
    async def convert_batch_inference_data(self, inference_data_list: List[Dict[str, Any]]) -> List[ConversionResult]:
        """æ‰¹é‡è½¬æ¢æ¨ç†æ•°æ®"""
        pass
    
    @abstractmethod
    async def validate_inference_data(self, inference_data: Dict[str, Any]) -> ValidationResult:
        """éªŒè¯æ¨ç†æ•°æ®"""
        pass


class InferenceDataConverter(BaseInferenceDataConverter):
    """æ¨ç†æ•°æ®è½¬æ¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è½¬æ¢å™¨"""
        self.required_fields = ['question', 'answer', 'contexts']
        self.optional_fields = ['ground_truth', 'reference', 'id']
        logger.info("æ¨ç†æ•°æ®è½¬æ¢å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def convert_inference_data(self, inference_data: Dict[str, Any]) -> ConversionResult:
        """è½¬æ¢æ¨ç†æ•°æ®"""
        try:
            # éªŒè¯æ¨ç†æ•°æ®
            validation = await self.validate_inference_data(inference_data)
            if not validation.is_valid:
                return ConversionResult(
                    success=False,
                    error_message=f"æ¨ç†æ•°æ®éªŒè¯å¤±è´¥: {'; '.join(validation.errors)}",
                    extracted_fields={},
                    processing_info={'validation_errors': validation.errors}
                )
            
            # æå–æ¨ç†å­—æ®µ
            extracted_fields = self._extract_inference_fields(inference_data)
            
            # åˆ›å»º RAGAS æ ·æœ¬
            sample = self._create_ragas_sample(extracted_fields)
            
            # æ”¶é›†å¤„ç†ä¿¡æ¯
            processing_info = {
                'original_inference_data': inference_data,
                'extracted_fields': extracted_fields,
                'field_mapping': self._get_field_mapping(),
                'conversion_timestamp': datetime.now().isoformat()
            }
            
            return ConversionResult(
                success=True,
                sample=sample,
                extracted_fields=extracted_fields,
                processing_info=processing_info
            )
            
        except Exception as e:
            logger.error(f"æ¨ç†æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return ConversionResult(
                success=False,
                error_message=str(e),
                extracted_fields={},
                processing_info={'error': str(e)}
            )
    
    def _extract_inference_fields(self, inference_data: Dict[str, Any]) -> Dict[str, Any]:
        """æå–æ¨ç†å­—æ®µ"""
        extracted = {}
        
        # æå–é—®é¢˜ï¼ˆæ£€æŸ¥é¡¹ç›®æ¨èçš„é—®é¢˜ï¼‰
        extracted['question'] = self._extract_question(inference_data)
        
        # æå–ç­”æ¡ˆï¼ˆæ¨èçš„æ£€æŸ¥é¡¹ç›®ï¼‰
        extracted['answer'] = self._extract_answer(inference_data)
        
        # æå–ä¸Šä¸‹æ–‡ï¼ˆæ¨ç†ä¾æ®ï¼‰
        extracted['contexts'] = self._extract_contexts(inference_data)
        
        # æå–æ ‡å‡†ç­”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
        extracted['ground_truth'] = self._extract_ground_truth(inference_data)
        
        # æå–ID
        extracted['id'] = self._extract_id(inference_data)
        
        return extracted
    
    def _extract_question(self, inference_data: Dict[str, Any]) -> str:
        """æå–é—®é¢˜å­—æ®µ"""
        # å¯èƒ½çš„å­—æ®µå
        question_fields = [
            'question', 'query', 'user_input', 'clinical_query',
            'inference_question', 'recommendation_question'
        ]
        
        for field in question_fields:
            if field in inference_data and inference_data[field]:
                return str(inference_data[field]).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é—®é¢˜å­—æ®µï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
    
    def _extract_answer(self, inference_data: Dict[str, Any]) -> str:
        """æå–ç­”æ¡ˆå­—æ®µï¼ˆæ¨èçš„æ£€æŸ¥é¡¹ç›®ï¼‰"""
        # å¯èƒ½çš„å­—æ®µå
        answer_fields = [
            'answer', 'response', 'result', 'recommendation',
            'recommended_procedures', 'suggested_tests', 'inference_result'
        ]
        
        for field in answer_fields:
            if field in inference_data and inference_data[field]:
                answer = inference_data[field]
                
                # å¦‚æœç­”æ¡ˆæ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if isinstance(answer, list):
                    return '\n'.join([str(item) for item in answer])
                
                # å¦‚æœç­”æ¡ˆæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬å†…å®¹
                if isinstance(answer, dict):
                    text_fields = ['text', 'content', 'description', 'name']
                    for text_field in text_fields:
                        if text_field in answer:
                            return str(answer[text_field]).strip()
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡æœ¬å­—æ®µï¼Œè¿”å›æ•´ä¸ªå­—å…¸çš„å­—ç¬¦ä¸²è¡¨ç¤º
                    return str(answer)
                
                return str(answer).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆå­—æ®µï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
    
    def _extract_contexts(self, inference_data: Dict[str, Any]) -> List[str]:
        """æå–ä¸Šä¸‹æ–‡å­—æ®µï¼ˆæ¨ç†ä¾æ®ï¼‰"""
        # å¯èƒ½çš„å­—æ®µå
        context_fields = [
            'contexts', 'retrieved_contexts', 'context', 'evidence',
            'inference_context', 'reasoning_context', 'supporting_evidence'
        ]
        
        for field in context_fields:
            if field in inference_data and inference_data[field]:
                contexts = inference_data[field]
                
                # ç¡®ä¿æ˜¯åˆ—è¡¨
                if isinstance(contexts, str):
                    contexts = [contexts]
                elif not isinstance(contexts, list):
                    contexts = [str(contexts)]
                
                # è¿‡æ»¤ç©ºä¸Šä¸‹æ–‡
                contexts = [str(ctx).strip() for ctx in contexts if ctx and str(ctx).strip()]
                
                if contexts:
                    return contexts
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸Šä¸‹æ–‡å­—æ®µï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []
    
    def _extract_ground_truth(self, inference_data: Dict[str, Any]) -> str:
        """æå–æ ‡å‡†ç­”æ¡ˆå­—æ®µ"""
        # å¯èƒ½çš„å­—æ®µå
        ground_truth_fields = [
            'ground_truth', 'reference', 'expected_answer', 'correct_answer',
            'standard_answer', 'reference_answer'
        ]
        
        for field in ground_truth_fields:
            if field in inference_data and inference_data[field]:
                return str(inference_data[field]).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†ç­”æ¡ˆå­—æ®µï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""
    
    def _extract_id(self, inference_data: Dict[str, Any]) -> str:
        """æå–IDå­—æ®µ"""
        # å¯èƒ½çš„å­—æ®µå
        id_fields = ['id', 'sample_id', 'inference_id', 'record_id']
        
        for field in id_fields:
            if field in inference_data and inference_data[field]:
                return str(inference_data[field])
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°IDå­—æ®µï¼Œç”Ÿæˆä¸€ä¸ª
        return f"inference_{hash(str(inference_data))}"
    
    def _create_ragas_sample(self, extracted_fields: Dict[str, Any]) -> SingleTurnSample:
        """åˆ›å»º RAGAS æ ·æœ¬"""
        return SingleTurnSample(
            user_input=extracted_fields.get('question', ''),
            response=extracted_fields.get('answer', ''),
            retrieved_contexts=extracted_fields.get('contexts', []),
            reference=extracted_fields.get('ground_truth', '')
        )
    
    def _get_field_mapping(self) -> Dict[str, List[str]]:
        """è·å–å­—æ®µæ˜ å°„ä¿¡æ¯"""
        return {
            'question_fields': ['question', 'query', 'user_input', 'clinical_query'],
            'answer_fields': ['answer', 'response', 'result', 'recommendation'],
            'context_fields': ['contexts', 'retrieved_contexts', 'context', 'evidence'],
            'ground_truth_fields': ['ground_truth', 'reference', 'expected_answer']
        }
    
    async def convert_batch_inference_data(self, inference_data_list: List[Dict[str, Any]]) -> List[ConversionResult]:
        """æ‰¹é‡è½¬æ¢æ¨ç†æ•°æ®"""
        results = []
        
        for i, inference_data in enumerate(inference_data_list):
            try:
                logger.info(f"è½¬æ¢æ¨ç†æ•°æ® {i+1}/{len(inference_data_list)}")
                result = await self.convert_inference_data(inference_data)
                results.append(result)
            except Exception as e:
                logger.error(f"æ¨ç†æ•°æ® {i+1} è½¬æ¢å¤±è´¥: {e}")
                results.append(ConversionResult(
                    success=False,
                    error_message=f"æ¨ç†æ•°æ® {i+1} è½¬æ¢å¤±è´¥: {str(e)}",
                    extracted_fields={},
                    processing_info={'row_index': i, 'error': str(e)}
                ))
        
        return results
    
    async def validate_inference_data(self, inference_data: Dict[str, Any]) -> ValidationResult:
        """éªŒè¯æ¨ç†æ•°æ®"""
        errors = []
        warnings = []
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        question = self._extract_question(inference_data)
        if not question:
            errors.append("ç¼ºå°‘é—®é¢˜å­—æ®µï¼ˆquestion/query/user_inputç­‰ï¼‰")
        
        answer = self._extract_answer(inference_data)
        if not answer:
            errors.append("ç¼ºå°‘ç­”æ¡ˆå­—æ®µï¼ˆanswer/response/resultç­‰ï¼‰")
        
        contexts = self._extract_contexts(inference_data)
        if not contexts:
            warnings.append("ç¼ºå°‘ä¸Šä¸‹æ–‡å­—æ®µï¼ˆcontexts/retrieved_contextsç­‰ï¼‰")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        if question and len(question.strip()) < 3:
            warnings.append("é—®é¢˜è¿‡çŸ­ï¼Œå¯èƒ½å½±å“è¯„æµ‹è´¨é‡")
        
        if answer and len(answer.strip()) < 5:
            warnings.append("ç­”æ¡ˆè¿‡çŸ­ï¼Œå¯èƒ½å½±å“è¯„æµ‹è´¨é‡")
        
        if contexts and len(contexts) > 10:
            warnings.append("ä¸Šä¸‹æ–‡æ•°é‡è¿‡å¤šï¼Œå¯èƒ½å½±å“å¤„ç†æ•ˆç‡")
        
        return ValidationResult(
            is_valid=len(errors) == 0,
            errors=errors,
            warnings=warnings
        )
    
    async def get_conversion_statistics(self, results: List[ConversionResult]) -> Dict[str, Any]:
        """è·å–è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        if not results:
            return {}
        
        total = len(results)
        successful = sum(1 for r in results if r.success)
        failed = total - successful
        
        # ç»Ÿè®¡å­—æ®µæå–æƒ…å†µ
        field_stats = {
            'question_extracted': 0,
            'answer_extracted': 0,
            'contexts_extracted': 0,
            'ground_truth_extracted': 0
        }
        
        for result in results:
            if result.success and result.extracted_fields:
                if result.extracted_fields.get('question'):
                    field_stats['question_extracted'] += 1
                if result.extracted_fields.get('answer'):
                    field_stats['answer_extracted'] += 1
                if result.extracted_fields.get('contexts'):
                    field_stats['contexts_extracted'] += 1
                if result.extracted_fields.get('ground_truth'):
                    field_stats['ground_truth_extracted'] += 1
        
        return {
            'total_samples': total,
            'successful_conversions': successful,
            'failed_conversions': failed,
            'success_rate': successful / total if total > 0 else 0,
            'field_extraction_stats': field_stats
        }


# å…¼å®¹æ€§å‡½æ•°
def create_inference_data_converter() -> InferenceDataConverter:
    """åˆ›å»ºæ¨ç†æ•°æ®è½¬æ¢å™¨å®ä¾‹"""
    return InferenceDataConverter()


if __name__ == "__main__":
    # æµ‹è¯•æ¨ç†æ•°æ®è½¬æ¢å™¨
    print("ğŸš€ æµ‹è¯•æ¨ç†æ•°æ®è½¬æ¢å™¨")
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    async def test_converter():
        try:
            # åˆ›å»ºè½¬æ¢å™¨
            converter = create_inference_data_converter()
            print("âœ… æ¨ç†æ•°æ®è½¬æ¢å™¨åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•æ•°æ® - æ£€æŸ¥é¡¹ç›®æ¨èæ¨ç†æ•°æ®
            test_inference_data = {
                "id": "inference_001",
                "question": "æ‚£è€…å‡ºç°èƒ¸ç—›ç—‡çŠ¶ï¼Œéœ€è¦æ¨èå“ªäº›æ£€æŸ¥é¡¹ç›®ï¼Ÿ",
                "answer": "å»ºè®®è¿›è¡Œä»¥ä¸‹æ£€æŸ¥ï¼š1. å¿ƒç”µå›¾ 2. èƒ¸éƒ¨Xå…‰ 3. å¿ƒè‚Œé…¶è°± 4. è¡€å¸¸è§„",
                "contexts": [
                    "èƒ¸ç—›æ˜¯å¸¸è§ç—‡çŠ¶ï¼Œéœ€è¦æ’é™¤å¿ƒè„ç–¾ç—…",
                    "å¿ƒç”µå›¾å¯ä»¥æ£€æµ‹å¿ƒå¾‹å¼‚å¸¸",
                    "èƒ¸éƒ¨Xå…‰å¯ä»¥è§‚å¯Ÿè‚ºéƒ¨æƒ…å†µ"
                ],
                "ground_truth": "èƒ¸ç—›æ‚£è€…åº”è¿›è¡Œå¿ƒç”µå›¾ã€èƒ¸éƒ¨Xå…‰ã€å¿ƒè‚Œé…¶è°±æ£€æŸ¥"
            }
            
            # è½¬æ¢æ¨ç†æ•°æ®
            result = await converter.convert_inference_data(test_inference_data)
            
            if result.success:
                print("âœ… æ¨ç†æ•°æ®è½¬æ¢æˆåŠŸ")
                print(f"   æå–çš„å­—æ®µ: {result.extracted_fields}")
                print(f"   å¤„ç†ä¿¡æ¯: {result.processing_info}")
                
                # éªŒè¯æ•°æ®
                validation = await converter.validate_inference_data(test_inference_data)
                print(f"   éªŒè¯ç»“æœ: {'é€šè¿‡' if validation.is_valid else 'å¤±è´¥'}")
                if validation.warnings:
                    print(f"   è­¦å‘Š: {validation.warnings}")
            else:
                print(f"âŒ æ¨ç†æ•°æ®è½¬æ¢å¤±è´¥: {result.error_message}")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    asyncio.run(test_converter())























