#!/usr/bin/env python3
"""
LLMè¾“å‡ºè°ƒè¯•è„šæœ¬
ä¸“é—¨è°ƒè¯•RAGASè¯„æµ‹ä¸­LLMçš„è¾“å‡ºå’Œè§£æé—®é¢˜
"""
import os
import sys
import json
import logging
from pathlib import Path

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['NEST_ASYNCIO_DISABLE'] = '1'
os.environ['UVLOOP_DISABLE'] = '1'

# åŠ è½½.envæ–‡ä»¶
env_file = Path(__file__).parent / '.env'
if env_file.exists():
    with open(env_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                os.environ[key] = value

sys.path.insert(0, str(Path(__file__).parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

def debug_single_metric():
    """è°ƒè¯•å•ä¸ªæŒ‡æ ‡çš„LLMè¾“å‡º"""
    print("=" * 70)
    print("LLMè¾“å‡ºè°ƒè¯•")
    print("=" * 70)
    
    try:
        from ragas.dataset_schema import SingleTurnSample
        from ragas.metrics import Faithfulness, ContextPrecision, ContextRecall
        from langchain_openai import ChatOpenAI
        
        # åˆå§‹åŒ–LLM
        llm = ChatOpenAI(
            model="Qwen/Qwen2.5-32B-Instruct",
            api_key=os.getenv("SILICONFLOW_API_KEY"),
            base_url="https://api.siliconflow.cn/v1",
            temperature=0.1,
            timeout=60,
            max_retries=2
        )
        
        # æµ‹è¯•æ•°æ®
        test_data = {
            "question": "ç³–å°¿ç—…æ‚£è€…çš„é¥®é£Ÿç®¡ç†å»ºè®®ï¼Ÿ",
            "answer": "ç³–å°¿ç—…æ‚£è€…é¥®é£Ÿç®¡ç†ï¼š1. æ§åˆ¶æ€»çƒ­é‡ 2. åˆç†åˆ†é…ä¸‰å¤§è¥å…»ç´  3. å®šæ—¶å®šé‡è¿›é¤",
            "contexts": [
                "ç³–å°¿ç—…éœ€è¦ä¸¥æ ¼çš„é¥®é£Ÿæ§åˆ¶",
                "è¥å…»å‡è¡¡å¯¹è¡€ç³–æ§åˆ¶å¾ˆé‡è¦"
            ],
            "ground_truth": "ç³–å°¿ç—…æ‚£è€…åº”è¯¥æ§åˆ¶é¥®é£Ÿ"
        }
        
        sample = SingleTurnSample(
            user_input=test_data["question"],
            response=test_data["answer"],
            retrieved_contexts=test_data["contexts"],
            reference=test_data["ground_truth"]
        )
        
        print(f"\\nğŸ“‹ æµ‹è¯•æ•°æ®:")
        print(f"   é—®é¢˜: {test_data['question']}")
        print(f"   ç­”æ¡ˆ: {test_data['answer']}")
        print(f"   ä¸Šä¸‹æ–‡: {test_data['contexts']}")
        print(f"   æ ‡å‡†ç­”æ¡ˆ: {test_data['ground_truth']}")
        
        # æµ‹è¯•Context Precision
        print(f"\\nğŸ” æµ‹è¯• Context Precision...")
        try:
            context_precision = ContextPrecision(llm=llm)
            
            # æ‰‹åŠ¨è°ƒç”¨å†…éƒ¨æ–¹æ³•æ¥æŸ¥çœ‹LLMè¾“å‡º
            print("   è°ƒç”¨LLMè¿›è¡Œä¸Šä¸‹æ–‡ç²¾ç¡®åº¦è¯„ä¼°...")
            
            # ç›´æ¥è°ƒç”¨è¯„ä¼°
            score = context_precision.single_turn_score(sample)
            print(f"   Context Precision å¾—åˆ†: {score}")
            
        except Exception as e:
            print(f"   âŒ Context Precision å¤±è´¥: {e}")
            logger.error(f"Context Precision è¯¦ç»†é”™è¯¯: {e}", exc_info=True)
        
        # æµ‹è¯•Context Recall
        print(f"\\nğŸ” æµ‹è¯• Context Recall...")
        try:
            context_recall = ContextRecall(llm=llm)
            
            print("   è°ƒç”¨LLMè¿›è¡Œä¸Šä¸‹æ–‡å¬å›ç‡è¯„ä¼°...")
            score = context_recall.single_turn_score(sample)
            print(f"   Context Recall å¾—åˆ†: {score}")
            
        except Exception as e:
            print(f"   âŒ Context Recall å¤±è´¥: {e}")
            logger.error(f"Context Recall è¯¦ç»†é”™è¯¯: {e}", exc_info=True)
        
        # æµ‹è¯•Faithfulness
        print(f"\\nğŸ” æµ‹è¯• Faithfulness...")
        try:
            faithfulness = Faithfulness(llm=llm)
            
            print("   è°ƒç”¨LLMè¿›è¡Œå¿ å®åº¦è¯„ä¼°...")
            score = faithfulness.single_turn_score(sample)
            print(f"   Faithfulness å¾—åˆ†: {score}")
            
        except Exception as e:
            print(f"   âŒ Faithfulness å¤±è´¥: {e}")
            logger.error(f"Faithfulness è¯¦ç»†é”™è¯¯: {e}", exc_info=True)
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯: {e}", exc_info=True)

def test_llm_direct():
    """ç›´æ¥æµ‹è¯•LLMå“åº”"""
    print(f"\\nğŸ¤– ç›´æ¥æµ‹è¯•LLMå“åº”")
    
    try:
        from langchain_openai import ChatOpenAI
        from langchain.schema import HumanMessage
        
        llm = ChatOpenAI(
            model="Qwen/Qwen2.5-32B-Instruct",
            api_key=os.getenv("SILICONFLOW_API_KEY"),
            base_url="https://api.siliconflow.cn/v1",
            temperature=0.1,
            timeout=60,
            max_retries=2
        )
        
        # æµ‹è¯•ç®€å•çš„LLMè°ƒç”¨
        test_prompt = """è¯·å›ç­”ï¼šç³–å°¿ç—…æ‚£è€…çš„é¥®é£Ÿç®¡ç†å»ºè®®æ˜¯ä»€ä¹ˆï¼Ÿ
        
è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå¹¶ä¸”æ ¼å¼åŒ–ä¸ºJSONï¼š
{
  "answer": "ä½ çš„å›ç­”",
  "confidence": 0.9
}"""
        
        print(f"   å‘é€æç¤º: {test_prompt[:100]}...")
        
        response = llm.invoke([HumanMessage(content=test_prompt)])
        print(f"   LLMå“åº”: {response.content}")
        
        # å°è¯•è§£æJSON
        try:
            parsed = json.loads(response.content)
            print(f"   JSONè§£ææˆåŠŸ: {parsed}")
        except:
            print(f"   JSONè§£æå¤±è´¥ï¼ŒåŸå§‹å“åº”: {response.content}")
        
    except Exception as e:
        print(f"âŒ LLMæµ‹è¯•å¤±è´¥: {e}")
        logger.error(f"è¯¦ç»†é”™è¯¯: {e}", exc_info=True)

def main():
    """ä¸»å‡½æ•°"""
    # 1. è°ƒè¯•å•ä¸ªæŒ‡æ ‡
    debug_single_metric()
    
    # 2. ç›´æ¥æµ‹è¯•LLM
    test_llm_direct()
    
    print("\\n" + "=" * 70)
    print("ğŸ¯ LLMè°ƒè¯•å®Œæˆ")
    print("=" * 70)

if __name__ == "__main__":
    main()