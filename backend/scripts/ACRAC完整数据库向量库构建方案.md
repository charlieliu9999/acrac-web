#!/usr/bin/env python3
"""
ACRACå®Œæ•´æ•°æ®åº“å’Œå‘é‡åº“æ„å»ºè„šæœ¬
ä»CSVæ–‡ä»¶æ„å»ºå®Œæ•´çš„æ•°æ®åº“å’Œå‘é‡åµŒå…¥
"""
import sys
import os
from pathlib import Path
import argparse
import json
from datetime import datetime
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import psycopg2
import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CompleteDataBuilder:
    """å®Œæ•´æ•°æ®åº“å’Œå‘é‡åº“æ„å»ºå™¨"""
    
    def __init__(self, db_config: Dict = None):
        self.db_config = db_config or {
            "host": "localhost",
            "port": "5432", 
            "database": "acrac_db",
            "user": "postgres",
            "password": "password"
        }
        self.conn = None
        self.cursor = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'panels_created': 0,
            'topics_created': 0,
            'scenarios_created': 0,
            'procedures_created': 0,
            'recommendations_created': 0,
            'vectors_generated': 0,
            'errors': []
        }
        
        # IDè®¡æ•°å™¨
        self.id_counters = {
            'panel': 0,
            'topic': 0,
            'scenario': 0,
            'procedure': 0,
            'recommendation': 0
        }
        
        # ç¼“å­˜æ˜ å°„
        self.entity_cache = {
            'panels': {},      # name_key -> semantic_id
            'topics': {},      # name_key -> semantic_id
            'scenarios': {},   # desc_key -> semantic_id
            'procedures': {}   # name_key -> semantic_id
        }
    
    def connect(self) -> bool:
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = psycopg2.connect(**self.db_config)
            self.cursor = self.conn.cursor()
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.cursor:
            self.cursor.close()
        if self.conn:
            self.conn.close()
        logger.info("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def create_complete_schema(self) -> bool:
        """åˆ›å»ºå®Œæ•´çš„æ•°æ®åº“æ¶æ„"""
        logger.info("ğŸ—ï¸ åˆ›å»ºå®Œæ•´æ•°æ®åº“æ¶æ„...")
        
        try:
            # åˆ é™¤ç°æœ‰è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            drop_tables = [
                "DROP TABLE IF EXISTS vector_search_logs CASCADE;",
                "DROP TABLE IF EXISTS data_update_history CASCADE;",
                "DROP TABLE IF EXISTS clinical_recommendations CASCADE;",
                "DROP TABLE IF EXISTS procedure_dictionary CASCADE;",
                "DROP TABLE IF EXISTS clinical_scenarios CASCADE;",
                "DROP TABLE IF EXISTS topics CASCADE;",
                "DROP TABLE IF EXISTS panels CASCADE;"
            ]
            
            for drop_sql in drop_tables:
                self.cursor.execute(drop_sql)
            
            # åˆ›å»ºæ–°è¡¨
            schema_sqls = [
                # ç§‘å®¤è¡¨
                """
                CREATE TABLE panels (
                    id SERIAL PRIMARY KEY,
                    semantic_id VARCHAR(20) UNIQUE NOT NULL,
                    name_en VARCHAR(255) NOT NULL,
                    name_zh VARCHAR(255) NOT NULL,
                    description TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding VECTOR(1024)
                );
                """,
                
                # ä¸»é¢˜è¡¨
                """
                CREATE TABLE topics (
                    id SERIAL PRIMARY KEY,
                    semantic_id VARCHAR(20) UNIQUE NOT NULL,
                    panel_id INTEGER REFERENCES panels(id) ON DELETE CASCADE,
                    name_en VARCHAR(500) NOT NULL,
                    name_zh VARCHAR(500) NOT NULL,
                    description TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding VECTOR(1024)
                );
                """,
                
                # ä¸´åºŠåœºæ™¯è¡¨
                """
                CREATE TABLE clinical_scenarios (
                    id SERIAL PRIMARY KEY,
                    semantic_id VARCHAR(20) UNIQUE NOT NULL,
                    panel_id INTEGER REFERENCES panels(id) ON DELETE CASCADE,
                    topic_id INTEGER REFERENCES topics(id) ON DELETE CASCADE,
                    description_en TEXT NOT NULL,
                    description_zh TEXT NOT NULL,
                    clinical_context TEXT,
                    patient_population VARCHAR(100),
                    risk_level VARCHAR(50),
                    age_group VARCHAR(50),
                    gender VARCHAR(20),
                    pregnancy_status VARCHAR(50),
                    urgency_level VARCHAR(50),
                    symptom_category VARCHAR(100),
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding VECTOR(1024)
                );
                """,
                
                # æ£€æŸ¥é¡¹ç›®å­—å…¸è¡¨
                """
                CREATE TABLE procedure_dictionary (
                    id SERIAL PRIMARY KEY,
                    semantic_id VARCHAR(20) UNIQUE NOT NULL,
                    name_en VARCHAR(500) NOT NULL,
                    name_zh VARCHAR(500) NOT NULL,
                    modality VARCHAR(50),
                    body_part VARCHAR(100),
                    contrast_used BOOLEAN DEFAULT FALSE,
                    radiation_level VARCHAR(50),
                    exam_duration INTEGER,
                    preparation_required BOOLEAN DEFAULT FALSE,
                    standard_code VARCHAR(50),
                    icd10_code VARCHAR(20),
                    cpt_code VARCHAR(20),
                    description_en TEXT,
                    description_zh TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding VECTOR(1024)
                );
                """,
                
                # ä¸´åºŠæ¨èå…³ç³»è¡¨
                """
                CREATE TABLE clinical_recommendations (
                    id SERIAL PRIMARY KEY,
                    semantic_id VARCHAR(50) UNIQUE NOT NULL,
                    scenario_id VARCHAR(20) REFERENCES clinical_scenarios(semantic_id) ON DELETE CASCADE,
                    procedure_id VARCHAR(20) REFERENCES procedure_dictionary(semantic_id) ON DELETE CASCADE,
                    appropriateness_rating INTEGER CHECK (appropriateness_rating >= 1 AND appropriateness_rating <= 9),
                    appropriateness_category VARCHAR(100),
                    appropriateness_category_zh VARCHAR(100),
                    reasoning_en TEXT,
                    reasoning_zh TEXT,
                    evidence_level VARCHAR(50),
                    median_rating FLOAT,
                    rating_variance FLOAT,
                    consensus_level VARCHAR(50),
                    adult_radiation_dose VARCHAR(50),
                    pediatric_radiation_dose VARCHAR(50),
                    contraindications TEXT,
                    special_considerations TEXT,
                    pregnancy_safety VARCHAR(50),
                    is_generated BOOLEAN DEFAULT FALSE,
                    confidence_score FLOAT DEFAULT 1.0,
                    last_reviewed_date DATE,
                    reviewer_id INTEGER,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    embedding VECTOR(1024),
                    UNIQUE(scenario_id, procedure_id)
                );
                """,
                
                # å‘é‡æœç´¢æ—¥å¿—è¡¨
                """
                CREATE TABLE vector_search_logs (
                    id SERIAL PRIMARY KEY,
                    query_text TEXT NOT NULL,
                    query_type VARCHAR(50),
                    search_vector VECTOR(1024),
                    results_count INTEGER,
                    search_time_ms INTEGER,
                    user_id INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                """,
                
                # æ•°æ®æ›´æ–°å†å²è¡¨
                """
                CREATE TABLE data_update_history (
                    id SERIAL PRIMARY KEY,
                    table_name VARCHAR(50) NOT NULL,
                    record_id VARCHAR(50) NOT NULL,
                    operation VARCHAR(20) NOT NULL,
                    old_data JSONB,
                    new_data JSONB,
                    user_id INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                """
            ]
            
            for sql in schema_sqls:
                self.cursor.execute(sql)
            
            self.conn.commit()
            logger.info("âœ… æ•°æ®åº“æ¶æ„åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“æ¶æ„å¤±è´¥: {e}")
            self.conn.rollback()
            return False
    
    def create_indexes(self) -> bool:
        """åˆ›å»ºç´¢å¼•"""
        logger.info("ğŸ“Š åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
        
        try:
            index_sqls = [
                # åŸºç¡€ç´¢å¼•
                "CREATE INDEX idx_panels_semantic_id ON panels (semantic_id);",
                "CREATE INDEX idx_topics_semantic_id ON topics (semantic_id);",
                "CREATE INDEX idx_topics_panel_id ON topics (panel_id);",
                "CREATE INDEX idx_scenarios_semantic_id ON clinical_scenarios (semantic_id);",
                "CREATE INDEX idx_scenarios_panel_topic ON clinical_scenarios (panel_id, topic_id);",
                "CREATE INDEX idx_procedures_semantic_id ON procedure_dictionary (semantic_id);",
                "CREATE INDEX idx_procedures_modality ON procedure_dictionary (modality);",
                "CREATE INDEX idx_recommendations_semantic_id ON clinical_recommendations (semantic_id);",
                "CREATE INDEX idx_recommendations_scenario ON clinical_recommendations (scenario_id);",
                "CREATE INDEX idx_recommendations_procedure ON clinical_recommendations (procedure_id);",
                "CREATE INDEX idx_recommendations_rating ON clinical_recommendations (appropriateness_rating);",
                
                # å¤åˆç´¢å¼•
                "CREATE INDEX idx_scenarios_patient_features ON clinical_scenarios (patient_population, risk_level, age_group);",
                "CREATE INDEX idx_procedures_attributes ON procedure_dictionary (modality, body_part, contrast_used);",
                "CREATE INDEX idx_recommendations_quality ON clinical_recommendations (appropriateness_rating, evidence_level, confidence_score);",
                
                # å‘é‡ç´¢å¼•
                "CREATE INDEX idx_panels_embedding ON panels USING ivfflat (embedding vector_cosine_ops) WITH (lists = 50);",
                "CREATE INDEX idx_topics_embedding ON topics USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);",
                "CREATE INDEX idx_scenarios_embedding ON clinical_scenarios USING ivfflat (embedding vector_cosine_ops) WITH (lists = 500);",
                "CREATE INDEX idx_procedures_embedding ON procedure_dictionary USING ivfflat (embedding vector_cosine_ops) WITH (lists = 500);",
                "CREATE INDEX idx_recommendations_embedding ON clinical_recommendations USING ivfflat (embedding vector_cosine_ops) WITH (lists = 1000);"
            ]
            
            for sql in index_sqls:
                try:
                    self.cursor.execute(sql)
                    logger.info(f"   âœ… åˆ›å»ºç´¢å¼•")
                except Exception as e:
                    logger.warning(f"   âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
            
            self.conn.commit()
            logger.info("âœ… æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            self.conn.rollback()
            return False
    
    def load_csv_data(self, csv_path: str) -> pd.DataFrame:
        """åŠ è½½CSVæ•°æ®"""
        logger.info(f"ğŸ“‚ åŠ è½½CSVæ•°æ®: {csv_path}")
        
        try:
            if not os.path.exists(csv_path):
                raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            
            # å°è¯•ä¸åŒç¼–ç å’Œåˆ†éš”ç¬¦
            for encoding in ['utf-16', 'utf-8', 'gbk', 'gb2312']:
                for sep in ['\t', ',', ';']:
                    try:
                        df = pd.read_csv(csv_path, encoding=encoding, sep=sep)
                        if len(df.columns) >= 15:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                            logger.info(f"âœ… ä½¿ç”¨ç¼–ç  {encoding} å’Œåˆ†éš”ç¬¦ '{sep}' æˆåŠŸè¯»å–")
                            break
                    except Exception:
                        continue
                else:
                    continue
                break
            else:
                raise ValueError("æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼Œå°è¯•äº†å¤šç§ç¼–ç å’Œåˆ†éš”ç¬¦")
            
            # æ•°æ®æ¸…æ´—
            df = df.fillna('')
            
            # æ ‡å‡†åŒ–åˆ—å
            expected_columns = [
                'Panel', 'Panel Translation', 'Topic', 'Topic Translation',
                'Variant', 'Variant Translation', 'Appropriateness Category',
                'Appropriateness Category Translation', 'Rating', 'Median',
                'Procedure', 'Standardized', 'Recommendation', 'Recommendation Translation',
                'Generated', 'SOE', 'Adult RRL', 'Peds RRL'
            ]
            
            # æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
            missing_columns = [col for col in expected_columns[:12] if col not in df.columns]
            if missing_columns:
                raise ValueError(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            
            logger.info(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
            return df
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½CSVæ•°æ®å¤±è´¥: {e}")
            return None
    
    def build_complete_database(self, df: pd.DataFrame) -> bool:
        """æ„å»ºå®Œæ•´æ•°æ®åº“"""
        logger.info("ğŸš€ å¼€å§‹æ„å»ºå®Œæ•´æ•°æ®åº“...")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†æ•°æ®ï¼Œæå–å”¯ä¸€å®ä½“
            logger.info("ğŸ“ æ­¥éª¤1: é¢„å¤„ç†æ•°æ®")
            processed_data = self._preprocess_data(df)
            
            # ç¬¬äºŒæ­¥ï¼šæ„å»ºPanels
            logger.info("ğŸ“ æ­¥éª¤2: æ„å»ºPanels")
            self._build_panels(processed_data['panels'])
            
            # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºTopics
            logger.info("ğŸ“ æ­¥éª¤3: æ„å»ºTopics")
            self._build_topics(processed_data['topics'])
            
            # ç¬¬å››æ­¥ï¼šæ„å»ºClinical Scenarios
            logger.info("ğŸ“ æ­¥éª¤4: æ„å»ºClinical Scenarios")
            self._build_clinical_scenarios(processed_data['scenarios'])
            
            # ç¬¬äº”æ­¥ï¼šæ„å»ºProcedure Dictionary
            logger.info("ğŸ“ æ­¥éª¤5: æ„å»ºProcedure Dictionary")
            self._build_procedure_dictionary(processed_data['procedures'])
            
            # ç¬¬å…­æ­¥ï¼šæ„å»ºClinical Recommendations
            logger.info("ğŸ“ æ­¥éª¤6: æ„å»ºClinical Recommendations")
            self._build_clinical_recommendations(processed_data['recommendations'])
            
            # ç¬¬ä¸ƒæ­¥ï¼šç”Ÿæˆå‘é‡åµŒå…¥
            logger.info("ğŸ“ æ­¥éª¤7: ç”Ÿæˆå‘é‡åµŒå…¥")
            self._generate_all_embeddings()
            
            logger.info("âœ… å®Œæ•´æ•°æ®åº“æ„å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºæ•°æ®åº“å¤±è´¥: {e}")
            self.conn.rollback()
            return False
    
    def _preprocess_data(self, df: pd.DataFrame) -> Dict[str, List]:
        """é¢„å¤„ç†æ•°æ®ï¼Œæå–å”¯ä¸€å®ä½“"""
        logger.info("ğŸ”„ é¢„å¤„ç†æ•°æ®...")
        
        panels = {}
        topics = {}
        scenarios = {}
        procedures = {}
        recommendations = []
        
        for _, row in df.iterrows():
            # æå–Panel
            panel_key = f"{row['Panel']}|||{row['Panel Translation']}"
            if panel_key not in panels:
                panels[panel_key] = {
                    'name_en': row['Panel'],
                    'name_zh': row['Panel Translation']
                }
            
            # æå–Topic
            topic_key = f"{panel_key}|||{row['Topic']}|||{row['Topic Translation']}"
            if topic_key not in topics:
                topics[topic_key] = {
                    'panel_key': panel_key,
                    'name_en': row['Topic'],
                    'name_zh': row['Topic Translation']
                }
            
            # æå–Scenario
            scenario_key = f"{topic_key}|||{row['Variant']}|||{row['Variant Translation']}"
            if scenario_key not in scenarios:
                scenarios[scenario_key] = {
                    'panel_key': panel_key,
                    'topic_key': topic_key,
                    'description_en': row['Variant'],
                    'description_zh': row['Variant Translation']
                }
            
            # æå–Procedure
            proc_key = f"{row['Procedure']}|||{row['Standardized']}"
            if proc_key not in procedures:
                procedures[proc_key] = {
                    'name_en': row['Procedure'],
                    'name_zh': row['Standardized']
                }
            
            # æ„å»ºRecommendation
            recommendations.append({
                'scenario_key': scenario_key,
                'procedure_key': proc_key,
                'appropriateness_rating': self._safe_int(row.get('Rating')),
                'appropriateness_category': row.get('Appropriateness Category', ''),
                'appropriateness_category_zh': row.get('Appropriateness Category Translation', ''),
                'reasoning_en': row.get('Recommendation', ''),
                'reasoning_zh': row.get('Recommendation Translation', ''),
                'evidence_level': row.get('SOE', ''),
                'median_rating': self._safe_float(row.get('Median')),
                'adult_radiation_dose': row.get('Adult RRL', ''),
                'pediatric_radiation_dose': row.get('Peds RRL', ''),
                'is_generated': self._safe_bool(row.get('Generated'))
            })
        
        logger.info(f"   é¢„å¤„ç†å®Œæˆ: {len(panels)} Panels, {len(topics)} Topics, {len(scenarios)} Scenarios, {len(procedures)} Procedures, {len(recommendations)} Recommendations")
        
        return {
            'panels': list(panels.values()),
            'topics': list(topics.values()),
            'scenarios': list(scenarios.values()),
            'procedures': list(procedures.values()),
            'recommendations': recommendations
        }
    
    def _build_panels(self, panels_data: List[Dict]):
        """æ„å»ºPanels"""
        for panel_data in panels_data:
            self.id_counters['panel'] += 1
            semantic_id = f"P{self.id_counters['panel']:04d}"
            
            self.cursor.execute("""
                INSERT INTO panels (semantic_id, name_en, name_zh, is_active)
                VALUES (%s, %s, %s, %s)
                RETURNING id;
            """, (semantic_id, panel_data['name_en'], panel_data['name_zh'], True))
            
            panel_id = self.cursor.fetchone()[0]
            
            # ç¼“å­˜æ˜ å°„
            panel_key = f"{panel_data['name_en']}|||{panel_data['name_zh']}"
            self.entity_cache['panels'][panel_key] = semantic_id
            
            self.stats['panels_created'] += 1
        
        self.conn.commit()
        logger.info(f"   âœ… åˆ›å»º {len(panels_data)} ä¸ªPanels")
    
    def _build_topics(self, topics_data: List[Dict]):
        """æ„å»ºTopics"""
        for topic_data in topics_data:
            panel_semantic_id = self.entity_cache['panels'][topic_data['panel_key']]
            
            # è·å–panel_id
            self.cursor.execute("SELECT id FROM panels WHERE semantic_id = %s", (panel_semantic_id,))
            panel_id = self.cursor.fetchone()[0]
            
            self.id_counters['topic'] += 1
            semantic_id = f"T{self.id_counters['topic']:04d}"
            
            self.cursor.execute("""
                INSERT INTO topics (semantic_id, panel_id, name_en, name_zh, is_active)
                VALUES (%s, %s, %s, %s, %s)
                RETURNING id;
            """, (semantic_id, panel_id, topic_data['name_en'], topic_data['name_zh'], True))
            
            topic_id = self.cursor.fetchone()[0]
            
            # ç¼“å­˜æ˜ å°„
            topic_key = f"{topic_data['panel_key']}|||{topic_data['name_en']}|||{topic_data['name_zh']}"
            self.entity_cache['topics'][topic_key] = semantic_id
            
            self.stats['topics_created'] += 1
        
        self.conn.commit()
        logger.info(f"   âœ… åˆ›å»º {len(topics_data)} ä¸ªTopics")
    
    def _build_clinical_scenarios(self, scenarios_data: List[Dict]):
        """æ„å»ºClinical Scenarios"""
        for scenario_data in scenarios_data:
            panel_semantic_id = self.entity_cache['panels'][scenario_data['panel_key']]
            topic_semantic_id = self.entity_cache['topics'][scenario_data['topic_key']]
            
            # è·å–panel_idå’Œtopic_id
            self.cursor.execute("SELECT id FROM panels WHERE semantic_id = %s", (panel_semantic_id,))
            panel_id = self.cursor.fetchone()[0]
            self.cursor.execute("SELECT id FROM topics WHERE semantic_id = %s", (topic_semantic_id,))
            topic_id = self.cursor.fetchone()[0]
            
            self.id_counters['scenario'] += 1
            semantic_id = f"S{self.id_counters['scenario']:04d}"
            
            # æå–æ‚£è€…ç‰¹å¾
            patient_features = self._extract_patient_features(
                scenario_data['description_en'], 
                scenario_data['description_zh']
            )
            
            self.cursor.execute("""
                INSERT INTO clinical_scenarios 
                (semantic_id, panel_id, topic_id, description_en, description_zh,
                 patient_population, risk_level, age_group, gender, pregnancy_status,
                 urgency_level, symptom_category, is_active)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id;
            """, (semantic_id, panel_id, topic_id, scenario_data['description_en'], scenario_data['description_zh'],
                  patient_features['patient_population'], patient_features['risk_level'], 
                  patient_features['age_group'], patient_features['gender'], 
                  patient_features['pregnancy_status'], patient_features['urgency_level'],
                  patient_features['symptom_category'], True))
            
            scenario_id = self.cursor.fetchone()[0]
            
            # ç¼“å­˜æ˜ å°„
            scenario_key = f"{scenario_data['topic_key']}|||{scenario_data['description_en']}|||{scenario_data['description_zh']}"
            self.entity_cache['scenarios'][scenario_key] = semantic_id
            
            self.stats['scenarios_created'] += 1
        
        self.conn.commit()
        logger.info(f"   âœ… åˆ›å»º {len(scenarios_data)} ä¸ªClinical Scenarios")
    
    def _build_procedure_dictionary(self, procedures_data: List[Dict]):
        """æ„å»ºProcedure Dictionary"""
        for proc_data in procedures_data:
            self.id_counters['procedure'] += 1
            semantic_id = f"PR{self.id_counters['procedure']:04d}"
            
            # æå–æ£€æŸ¥å±æ€§
            attributes = self._extract_procedure_attributes(
                proc_data['name_en'], 
                proc_data['name_zh']
            )
            
            self.cursor.execute("""
                INSERT INTO procedure_dictionary 
                (semantic_id, name_en, name_zh, modality, body_part, contrast_used,
                 radiation_level, is_active)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id;
            """, (semantic_id, proc_data['name_en'], proc_data['name_zh'],
                  attributes['modality'], attributes['body_part'], attributes['contrast_used'],
                  attributes['radiation_level'], True))
            
            proc_id = self.cursor.fetchone()[0]
            
            # ç¼“å­˜æ˜ å°„
            proc_key = f"{proc_data['name_en']}|||{proc_data['name_zh']}"
            self.entity_cache['procedures'][proc_key] = semantic_id
            
            self.stats['procedures_created'] += 1
        
        self.conn.commit()
        logger.info(f"   âœ… åˆ›å»º {len(procedures_data)} ä¸ªProcedures")
    
    def _build_clinical_recommendations(self, recommendations_data: List[Dict]):
        """æ„å»ºClinical Recommendations"""
        for rec_data in recommendations_data:
            scenario_semantic_id = self.entity_cache['scenarios'][rec_data['scenario_key']]
            procedure_semantic_id = self.entity_cache['procedures'][rec_data['procedure_key']]
            
            self.id_counters['recommendation'] += 1
            semantic_id = f"CR{self.id_counters['recommendation']:06d}"
            
            # è¯„ä¼°å¦Šå¨ å®‰å…¨æ€§
            pregnancy_safety = self._assess_pregnancy_safety(
                rec_data['adult_radiation_dose'],
                rec_data['reasoning_zh']
            )
            
            self.cursor.execute("""
                INSERT INTO clinical_recommendations 
                (semantic_id, scenario_id, procedure_id, appropriateness_rating,
                 appropriateness_category, appropriateness_category_zh, reasoning_en, reasoning_zh,
                 evidence_level, median_rating, adult_radiation_dose, pediatric_radiation_dose,
                 pregnancy_safety, is_generated, confidence_score, is_active)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (scenario_id, procedure_id) DO NOTHING
                RETURNING id;
            """, (semantic_id, scenario_semantic_id, procedure_semantic_id, rec_data['appropriateness_rating'],
                  rec_data['appropriateness_category'], rec_data['appropriateness_category_zh'],
                  rec_data['reasoning_en'], rec_data['reasoning_zh'], rec_data['evidence_level'],
                  rec_data['median_rating'], rec_data['adult_radiation_dose'], rec_data['pediatric_radiation_dose'],
                  pregnancy_safety, rec_data['is_generated'], 1.0, True))
            
            result = self.cursor.fetchone()
            if result:
                self.stats['recommendations_created'] += 1
        
        self.conn.commit()
        logger.info(f"   âœ… åˆ›å»º {self.stats['recommendations_created']} ä¸ªClinical Recommendations")
    
    def _generate_all_embeddings(self):
        """ç”Ÿæˆæ‰€æœ‰å‘é‡åµŒå…¥"""
        logger.info("ğŸ§  ç”Ÿæˆå‘é‡åµŒå…¥...")
        
        # ç”ŸæˆPanelå‘é‡
        self._generate_panel_embeddings()
        
        # ç”ŸæˆTopicå‘é‡ï¼ˆå±‚æ¬¡åŒ–ï¼šåŒ…å«Panelä¿¡æ¯ï¼‰
        self._generate_topic_embeddings()
        
        # ç”ŸæˆScenarioå‘é‡ï¼ˆå±‚æ¬¡åŒ–ï¼šåŒ…å«Panel+Topicä¿¡æ¯ï¼‰
        self._generate_scenario_embeddings()
        
        # ç”ŸæˆProcedureå‘é‡ï¼ˆç‹¬ç«‹ï¼‰
        self._generate_procedure_embeddings()
        
        # ç”ŸæˆRecommendationå‘é‡ï¼ˆå®Œæ•´ä¸´åºŠå†³ç­–ï¼‰
        self._generate_recommendation_embeddings()
        
        logger.info(f"   âœ… ç”Ÿæˆ {self.stats['vectors_generated']} ä¸ªå‘é‡åµŒå…¥")
    
    def _generate_panel_embeddings(self):
        """ç”ŸæˆPanelå‘é‡"""
        self.cursor.execute("SELECT id, semantic_id, name_en, name_zh, description FROM panels;")
        panels = self.cursor.fetchall()
        
        for panel in panels:
            panel_id, semantic_id, name_en, name_zh, description = panel
            
            # æ„å»ºå‘é‡åŒ–æ–‡æœ¬
            text = f"ç§‘å®¤: {name_zh} {name_en} {description or ''}"
            
            # ç”Ÿæˆå‘é‡ï¼ˆå®é™…åº”ä½¿ç”¨ä¸“ä¸šæ¨¡å‹ï¼‰
            embedding = np.random.rand(1024).tolist()
            
            self.cursor.execute("""
                UPDATE panels SET embedding = %s WHERE id = %s;
            """, (embedding, panel_id))
            
            self.stats['vectors_generated'] += 1
        
        self.conn.commit()
    
    def _generate_topic_embeddings(self):
        """ç”ŸæˆTopicå‘é‡ï¼ˆå±‚æ¬¡åŒ–ï¼‰"""
        self.cursor.execute("""
            SELECT t.id, t.semantic_id, t.name_en, t.name_zh, t.description,
                   p.name_zh as panel_name_zh, p.name_en as panel_name_en
            FROM topics t
            JOIN panels p ON t.panel_id = p.id;
        """)
        topics = self.cursor.fetchall()
        
        for topic in topics:
            topic_id, semantic_id, name_en, name_zh, description, panel_name_zh, panel_name_en = topic
            
            # æ„å»ºå±‚æ¬¡åŒ–å‘é‡åŒ–æ–‡æœ¬
            text = f"ç§‘å®¤: {panel_name_zh} {panel_name_en} | ä¸»é¢˜: {name_zh} {name_en} {description or ''}"
            
            # ç”Ÿæˆå‘é‡
            embedding = np.random.rand(1024).tolist()
            
            self.cursor.execute("""
                UPDATE topics SET embedding = %s WHERE id = %s;
            """, (embedding, topic_id))
            
            self.stats['vectors_generated'] += 1
        
        self.conn.commit()
    
    def _generate_scenario_embeddings(self):
        """ç”ŸæˆScenarioå‘é‡ï¼ˆå±‚æ¬¡åŒ–ï¼‰"""
        self.cursor.execute("""
            SELECT s.id, s.semantic_id, s.description_en, s.description_zh, s.clinical_context,
                   s.patient_population, s.risk_level, s.age_group, s.gender, s.pregnancy_status,
                   p.name_zh as panel_name, t.name_zh as topic_name
            FROM clinical_scenarios s
            JOIN topics t ON s.topic_id = t.id
            JOIN panels p ON s.panel_id = p.id;
        """)
        scenarios = self.cursor.fetchall()
        
        for scenario in scenarios:
            (scenario_id, semantic_id, desc_en, desc_zh, clinical_context,
             patient_pop, risk_level, age_group, gender, pregnancy_status,
             panel_name, topic_name) = scenario
            
            # æ„å»ºå®Œæ•´çš„å±‚æ¬¡åŒ–å‘é‡åŒ–æ–‡æœ¬
            text_parts = [
                f"ç§‘å®¤: {panel_name}",
                f"ä¸»é¢˜: {topic_name}",
                f"ä¸´åºŠåœºæ™¯: {desc_zh}",
                f"æ‚£è€…äººç¾¤: {patient_pop or ''}",
                f"é£é™©ç­‰çº§: {risk_level or ''}",
                f"å¹´é¾„ç»„: {age_group or ''}",
                f"æ€§åˆ«: {gender or ''}",
                f"å¦Šå¨ çŠ¶æ€: {pregnancy_status or ''}",
                f"ä¸´åºŠä¸Šä¸‹æ–‡: {clinical_context or ''}"
            ]
            
            text = " | ".join([part for part in text_parts if not part.endswith(': ')])
            
            # ç”Ÿæˆå‘é‡
            embedding = np.random.rand(1024).tolist()
            
            self.cursor.execute("""
                UPDATE clinical_scenarios SET embedding = %s WHERE id = %s;
            """, (embedding, scenario_id))
            
            self.stats['vectors_generated'] += 1
        
        self.conn.commit()
    
    def _generate_procedure_embeddings(self):
        """ç”ŸæˆProcedureå‘é‡ï¼ˆç‹¬ç«‹ï¼‰"""
        self.cursor.execute("""
            SELECT id, semantic_id, name_en, name_zh, modality, body_part, 
                   contrast_used, radiation_level, description_zh
            FROM procedure_dictionary;
        """)
        procedures = self.cursor.fetchall()
        
        for procedure in procedures:
            (proc_id, semantic_id, name_en, name_zh, modality, body_part,
             contrast_used, radiation_level, description) = procedure
            
            # æ„å»ºæ£€æŸ¥é¡¹ç›®å‘é‡åŒ–æ–‡æœ¬
            text_parts = [
                f"æ£€æŸ¥é¡¹ç›®: {name_zh}",
                f"æ£€æŸ¥æ–¹å¼: {modality or ''}",
                f"æ£€æŸ¥éƒ¨ä½: {body_part or ''}",
                f"å¯¹æ¯”å‰‚: {'ä½¿ç”¨' if contrast_used else 'ä¸ä½¿ç”¨'}",
                f"è¾å°„ç­‰çº§: {radiation_level or ''}",
                f"æè¿°: {description or ''}"
            ]
            
            text = " | ".join([part for part in text_parts if not part.endswith(': ')])
            
            # ç”Ÿæˆå‘é‡
            embedding = np.random.rand(1024).tolist()
            
            self.cursor.execute("""
                UPDATE procedure_dictionary SET embedding = %s WHERE id = %s;
            """, (embedding, proc_id))
            
            self.stats['vectors_generated'] += 1
        
        self.conn.commit()
    
    def _generate_recommendation_embeddings(self):
        """ç”ŸæˆRecommendationå‘é‡ï¼ˆå®Œæ•´ä¸´åºŠå†³ç­–ï¼‰"""
        self.cursor.execute("""
            SELECT 
                cr.id, cr.semantic_id, cr.appropriateness_rating, cr.reasoning_zh, cr.evidence_level,
                s.description_zh as scenario_desc, s.patient_population, s.risk_level, s.age_group,
                pd.name_zh as proc_name, pd.modality, pd.body_part,
                p.name_zh as panel_name, t.name_zh as topic_name
            FROM clinical_recommendations cr
            JOIN clinical_scenarios s ON cr.scenario_id = s.semantic_id
            JOIN procedure_dictionary pd ON cr.procedure_id = pd.semantic_id
            JOIN topics t ON s.topic_id = t.id
            JOIN panels p ON s.panel_id = p.id;
        """)
        recommendations = self.cursor.fetchall()
        
        for rec in recommendations:
            (rec_id, semantic_id, rating, reasoning, evidence_level,
             scenario_desc, patient_pop, risk_level, age_group,
             proc_name, modality, body_part, panel_name, topic_name) = rec
            
            # æ„å»ºå®Œæ•´ä¸´åºŠå†³ç­–å‘é‡åŒ–æ–‡æœ¬
            text_parts = [
                f"ç§‘å®¤: {panel_name}",
                f"ä¸»é¢˜: {topic_name}",
                f"ä¸´åºŠåœºæ™¯: {scenario_desc}",
                f"æ‚£è€…äººç¾¤: {patient_pop or ''}",
                f"é£é™©ç­‰çº§: {risk_level or ''}",
                f"å¹´é¾„ç»„: {age_group or ''}",
                f"æ£€æŸ¥é¡¹ç›®: {proc_name}",
                f"æ£€æŸ¥æ–¹å¼: {modality or ''}",
                f"æ£€æŸ¥éƒ¨ä½: {body_part or ''}",
                f"é€‚å®œæ€§è¯„åˆ†: {rating}åˆ†",
                f"è¯æ®å¼ºåº¦: {evidence_level or ''}",
                f"æ¨èç†ç”±: {reasoning or ''}"
            ]
            
            text = " | ".join([part for part in text_parts if not part.endswith(': ')])
            
            # ç”Ÿæˆå‘é‡
            embedding = np.random.rand(1024).tolist()
            
            self.cursor.execute("""
                UPDATE clinical_recommendations SET embedding = %s WHERE id = %s;
            """, (embedding, rec_id))
            
            self.stats['vectors_generated'] += 1
        
        self.conn.commit()
    
    # è¾…åŠ©æ–¹æ³•
    def _safe_int(self, value) -> Optional[int]:
        """å®‰å…¨è½¬æ¢ä¸ºæ•´æ•°"""
        try:
            return int(float(value)) if value and str(value).strip() else None
        except (ValueError, TypeError):
            return None
    
    def _safe_float(self, value) -> Optional[float]:
        """å®‰å…¨è½¬æ¢ä¸ºæµ®ç‚¹æ•°"""
        try:
            return float(value) if value and str(value).strip() else None
        except (ValueError, TypeError):
            return None
    
    def _safe_bool(self, value) -> bool:
        """å®‰å…¨è½¬æ¢ä¸ºå¸ƒå°”å€¼"""
        if not value:
            return False
        return str(value).lower() in ['true', '1', 'yes', 'æ˜¯', 'çœŸ']
    
    def _extract_patient_features(self, desc_en: str, desc_zh: str) -> Dict[str, str]:
        """æå–æ‚£è€…ç‰¹å¾"""
        text = f"{desc_en} {desc_zh}".lower()
        
        # æ‚£è€…äººç¾¤
        patient_population = 'ä¸€èˆ¬äººç¾¤'
        if any(keyword in text for keyword in ['pregnant', 'pregnancy', 'å­•å¦‡', 'å¦Šå¨ ']):
            patient_population = 'å­•å¦‡'
        elif any(keyword in text for keyword in ['pediatric', 'child', 'children', 'å„¿ç«¥', 'å°å„¿']):
            patient_population = 'å„¿ç«¥'
        elif any(keyword in text for keyword in ['elderly', 'geriatric', 'è€å¹´', 'è€äºº']):
            patient_population = 'è€å¹´'
        elif any(keyword in text for keyword in ['adult', 'adults', 'æˆäºº']):
            patient_population = 'æˆäºº'
        
        # é£é™©ç­‰çº§
        risk_level = 'æœªæŒ‡å®š'
        if any(keyword in text for keyword in ['high risk', 'high-risk', 'é«˜é£é™©', 'é«˜å±']):
            risk_level = 'é«˜é£é™©'
        elif any(keyword in text for keyword in ['moderate risk', 'intermediate risk', 'ä¸­é£é™©', 'ä¸­å±']):
            risk_level = 'ä¸­é£é™©'
        elif any(keyword in text for keyword in ['low risk', 'low-risk', 'ä½é£é™©', 'ä½å±']):
            risk_level = 'ä½é£é™©'
        elif any(keyword in text for keyword in ['average risk', 'å¹³å‡é£é™©', 'ä¸€èˆ¬é£é™©']):
            risk_level = 'å¹³å‡é£é™©'
        
        # å¹´é¾„ç»„
        age_group = 'æœªæŒ‡å®š'
        age_patterns = [
            ('40å²ä»¥ä¸Š', ['40 years or older', 'â‰¥40', '40å²ä»¥ä¸Š', '40å²åŠä»¥ä¸Š']),
            ('30å²ä»¥ä¸Š', ['30 years or older', 'â‰¥30', '30å²ä»¥ä¸Š', '30å²åŠä»¥ä¸Š']),
            ('25å²ä»¥ä¸Š', ['25 years or older', 'â‰¥25', '25å²ä»¥ä¸Š', '25å²åŠä»¥ä¸Š']),
            ('25å²ä»¥ä¸‹', ['less than 25', '<25', '25å²ä»¥ä¸‹']),
            ('30å²ä»¥ä¸‹', ['less than 30', '<30', '30å²ä»¥ä¸‹'])
        ]
        
        for age_group_name, patterns in age_patterns:
            if any(pattern in f"{desc_en} {desc_zh}" for pattern in patterns):
                age_group = age_group_name
                break
        
        # æ€§åˆ«
        gender = 'ä¸é™'
        if any(keyword in text for keyword in ['female', 'woman', 'women', 'å¥³æ€§', 'å¥³']):
            gender = 'å¥³æ€§'
        elif any(keyword in text for keyword in ['male', 'man', 'men', 'ç”·æ€§', 'ç”·']):
            gender = 'ç”·æ€§'
        
        # å¦Šå¨ çŠ¶æ€
        pregnancy_status = 'éå¦Šå¨ æœŸ'
        if any(keyword in text for keyword in ['pregnant', 'pregnancy', 'å¦Šå¨ ', 'å­•å¦‡', 'æ€€å­•']):
            pregnancy_status = 'å¦Šå¨ æœŸ'
        elif any(keyword in text for keyword in ['lactating', 'breastfeeding', 'å“ºä¹³', 'å“ºä¹³æœŸ']):
            pregnancy_status = 'å“ºä¹³æœŸ'
        
        # ç´§æ€¥ç¨‹åº¦
        urgency_level = 'æ‹©æœŸ'
        if any(keyword in text for keyword in ['emergency', 'urgent', 'acute', 'æ€¥è¯Š', 'ç´§æ€¥', 'æ€¥æ€§']):
            urgency_level = 'æ€¥è¯Š'
        
        # ç—‡çŠ¶åˆ†ç±»
        symptom_category = 'æœªæŒ‡å®š'
        symptom_keywords = {
            'ç–¼ç—›': ['pain', 'ache', 'ç–¼ç—›', 'ç—›'],
            'è‚¿å—': ['mass', 'lump', 'nodule', 'è‚¿å—', 'ç»“èŠ‚', 'åŒ…å—'],
            'å‡ºè¡€': ['bleeding', 'hemorrhage', 'å‡ºè¡€', 'è¡€'],
            'å‘çƒ­': ['fever', 'febrile', 'å‘çƒ­', 'å‘çƒ§'],
            'å‘¼å¸å›°éš¾': ['dyspnea', 'shortness of breath', 'å‘¼å¸å›°éš¾', 'æ°”ä¿ƒ'],
            'ç­›æŸ¥': ['screening', 'ç­›æŸ¥', 'ç­›é€‰']
        }
        
        for category, keywords in symptom_keywords.items():
            if any(keyword in text for keyword in keywords):
                symptom_category = category
                break
        
        return {
            'patient_population': patient_population,
            'risk_level': risk_level,
            'age_group': age_group,
            'gender': gender,
            'pregnancy_status': pregnancy_status,
            'urgency_level': urgency_level,
            'symptom_category': symptom_category
        }
    
    def _extract_procedure_attributes(self, name_en: str, name_zh: str) -> Dict[str, Any]:
        """æå–æ£€æŸ¥é¡¹ç›®å±æ€§"""
        text = f"{name_en} {name_zh}".upper()
        
        # æ£€æŸ¥æ–¹å¼
        modality_map = {
            'CT': ['CT', 'COMPUTED TOMOGRAPHY'],
            'MRI': ['MRI', 'MR', 'MAGNETIC RESONANCE'],
            'US': ['US', 'ULTRASOUND', 'è¶…å£°'],
            'XR': ['XR', 'X-RAY', 'RADIOGRAPHY', 'Xçº¿', 'å°„çº¿', 'DR'],
            'MG': ['MG', 'MAMMOGRAPHY', 'é’¼é¶'],
            'NM': ['SPECT', 'PET', 'SCINTIGRAPHY', 'æ ¸åŒ»å­¦', 'æ˜¾åƒ'],
            'RF': ['RF', 'FLUOROSCOPY', 'é€è§†'],
            'DSA': ['DSA', 'ANGIOGRAPHY', 'è¡€ç®¡é€ å½±']
        }
        
        modality = 'OTHER'
        for mod, keywords in modality_map.items():
            if any(keyword in text for keyword in keywords):
                modality = mod
                break
        
        # æ£€æŸ¥éƒ¨ä½
        body_parts = {
            'å¤´éƒ¨': ['HEAD', 'BRAIN', 'SKULL', 'å¤´', 'è„‘', 'é¢…'],
            'é¢ˆéƒ¨': ['NECK', 'CERVICAL', 'é¢ˆ', 'é¢ˆæ¤'],
            'èƒ¸éƒ¨': ['CHEST', 'THORAX', 'LUNG', 'CARDIAC', 'èƒ¸', 'è‚º', 'å¿ƒè„'],
            'è…¹éƒ¨': ['ABDOMEN', 'ABDOMINAL', 'LIVER', 'KIDNEY', 'è…¹', 'è‚', 'è‚¾'],
            'ç›†è…”': ['PELVIS', 'PELVIC', 'BLADDER', 'PROSTATE', 'ç›†', 'è†€èƒ±', 'å‰åˆ—è…º'],
            'è„ŠæŸ±': ['SPINE', 'SPINAL', 'VERTEBRA', 'è„Š', 'æ¤'],
            'å››è‚¢': ['EXTREMITY', 'ARM', 'LEG', 'LIMB', 'è‚¢', 'è‡‚', 'è…¿'],
            'ä¹³è…º': ['BREAST', 'MAMMARY', 'ä¹³è…º', 'ä¹³æˆ¿'],
            'è¡€ç®¡': ['VASCULAR', 'ARTERY', 'VEIN', 'è¡€ç®¡', 'åŠ¨è„‰', 'é™è„‰']
        }
        
        body_part = 'å…¶ä»–'
        for part, keywords in body_parts.items():
            if any(keyword in text for keyword in keywords):
                body_part = part
                break
        
        # å¯¹æ¯”å‰‚ä½¿ç”¨
        contrast_keywords = ['CONTRAST', 'ENHANCED', 'WITH IV', 'å¢å¼º', 'å¯¹æ¯”', 'é€ å½±']
        contrast_used = any(keyword in text for keyword in contrast_keywords)
        
        # è¾å°„ç­‰çº§
        radiation_level = 'æœªçŸ¥'
        if modality in ['US']:
            radiation_level = 'æ— '
        elif modality in ['XR', 'MG']:
            radiation_level = 'ä½'
        elif modality in ['CT']:
            radiation_level = 'ä¸­'
        elif modality in ['NM']:
            radiation_level = 'é«˜'
        elif modality in ['MRI']:
            radiation_level = 'æ— '
        
        return {
            'modality': modality,
            'body_part': body_part,
            'contrast_used': contrast_used,
            'radiation_level': radiation_level
        }
    
    def _assess_pregnancy_safety(self, radiation_dose: str, reasoning: str) -> str:
        """è¯„ä¼°å¦Šå¨ å®‰å…¨æ€§"""
        text = f"{radiation_dose} {reasoning}".lower()
        
        if any(keyword in text for keyword in ['contraindicated', 'not recommended', 'ç¦å¿Œ', 'ä¸æ¨è', 'ä¸å»ºè®®']):
            return 'ç¦å¿Œ'
        elif any(keyword in text for keyword in ['safe', 'appropriate', 'å®‰å…¨', 'é€‚å®œ']):
            return 'å®‰å…¨'
        elif any(keyword in text for keyword in ['caution', 'consider', 'è°¨æ…', 'è€ƒè™‘']):
            return 'è°¨æ…ä½¿ç”¨'
        else:
            return 'æœªè¯„ä¼°'
    
    def verify_build(self) -> Dict[str, Any]:
        """éªŒè¯æ„å»ºç»“æœ"""
        logger.info("ğŸ” éªŒè¯æ„å»ºç»“æœ...")
        
        try:
            verification = {}
            
            # ç»Ÿè®¡å„è¡¨è®°å½•æ•°
            tables = ['panels', 'topics', 'clinical_scenarios', 'procedure_dictionary', 'clinical_recommendations']
            for table in tables:
                self.cursor.execute(f"SELECT COUNT(*) FROM {table};")
                count = self.cursor.fetchone()[0]
                verification[f"{table}_count"] = count
            
            # æ£€æŸ¥å‘é‡åµŒå…¥è¦†ç›–ç‡
            for table in tables:
                self.cursor.execute(f"""
                    SELECT COUNT(*) as total, COUNT(embedding) as with_embedding 
                    FROM {table};
                """)
                total, with_embedding = self.cursor.fetchone()
                coverage = (with_embedding / total * 100) if total > 0 else 0
                verification[f"{table}_embedding_coverage"] = f"{with_embedding}/{total} ({coverage:.1f}%)"
            
            # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            self.cursor.execute("""
                SELECT COUNT(*) FROM clinical_recommendations cr
                WHERE cr.scenario_id NOT IN (SELECT semantic_id FROM clinical_scenarios)
                   OR cr.procedure_id NOT IN (SELECT semantic_id FROM procedure_dictionary);
            """)
            orphaned_recommendations = self.cursor.fetchone()[0]
            verification['orphaned_recommendations'] = orphaned_recommendations
            
            # ç¤ºä¾‹æ•°æ®
            self.cursor.execute("""
                SELECT 
                    cr.semantic_id,
                    p.name_zh as panel_name,
                    t.name_zh as topic_name,
                    s.description_zh as scenario_desc,
                    pd.name_zh as procedure_name,
                    cr.appropriateness_rating
                FROM clinical_recommendations cr
                JOIN clinical_scenarios s ON cr.scenario_id = s.semantic_id
                JOIN procedure_dictionary pd ON cr.procedure_id = pd.semantic_id
                JOIN topics t ON s.topic_id = t.id
                JOIN panels p ON s.panel_id = p.id
                ORDER BY cr.appropriateness_rating DESC
                LIMIT 5;
            """)
            
            examples = []
            for row in self.cursor.fetchall():
                examples.append({
                    'recommendation_id': row[0],
                    'panel': row[1],
                    'topic': row[2], 
                    'scenario': row[3][:50] + '...' if len(row[3]) > 50 else row[3],
                    'procedure': row[4],
                    'rating': row[5]
                })
            
            verification['examples'] = examples
            verification['build_stats'] = self.stats
            
            # è¾“å‡ºéªŒè¯ä¿¡æ¯
            logger.info("ğŸ“Š æ„å»ºç»Ÿè®¡:")
            for key, value in verification.items():
                if key.endswith('_count'):
                    logger.info(f"   {key}: {value}")
                elif key.endswith('_coverage'):
                    logger.info(f"   {key}: {value}")
            
            if orphaned_recommendations == 0:
                logger.info("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            else:
                logger.warning(f"âš ï¸ å‘ç° {orphaned_recommendations} æ¡å­¤ç«‹çš„æ¨èè®°å½•")
            
            logger.info("ğŸ“‹ ç¤ºä¾‹æ•°æ®:")
            for i, example in enumerate(examples, 1):
                logger.info(f"   {i}. {example['recommendation_id']}: {example['procedure']} | {example['scenario']} | è¯„åˆ†:{example['rating']}")
            
            return verification
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯æ„å»ºç»“æœå¤±è´¥: {e}")
            return {}

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ACRACå®Œæ•´æ•°æ®åº“å’Œå‘é‡åº“æ„å»ºå·¥å…·')
    parser.add_argument('action', choices=['build', 'verify', 'rebuild'], 
                       help='æ“ä½œç±»å‹: build(æ„å»º), verify(éªŒè¯), rebuild(é‡å»º)')
    parser.add_argument('--csv-file', default='../../ACR_data/ACR_final.csv',
                       help='CSVæ•°æ®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--skip-schema', action='store_true',
                       help='è·³è¿‡æ¶æ„åˆ›å»ºï¼ˆç”¨äºå¢é‡æ›´æ–°ï¼‰')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ ACRACå®Œæ•´æ•°æ®åº“å’Œå‘é‡åº“æ„å»ºå·¥å…·")
    logger.info("=" * 80)
    
    builder = CompleteDataBuilder()
    
    try:
        if not builder.connect():
            return 1
        
        if args.action in ['build', 'rebuild']:
            # åˆ›å»ºæ¶æ„
            if not args.skip_schema:
                logger.info("ğŸ“ æ­¥éª¤1: åˆ›å»ºæ•°æ®åº“æ¶æ„")
                if not builder.create_complete_schema():
                    return 1
                
                logger.info("ğŸ“ æ­¥éª¤2: åˆ›å»ºç´¢å¼•")
                if not builder.create_indexes():
                    return 1
            
            # åŠ è½½æ•°æ®
            logger.info("ğŸ“ æ­¥éª¤3: åŠ è½½CSVæ•°æ®")
            df = builder.load_csv_data(args.csv_file)
            if df is None:
                return 1
            
            # æ„å»ºæ•°æ®åº“
            logger.info("ğŸ“ æ­¥éª¤4: æ„å»ºå®Œæ•´æ•°æ®åº“")
            if not builder.build_complete_database(df):
                return 1
            
            # éªŒè¯ç»“æœ
            logger.info("ğŸ“ æ­¥éª¤5: éªŒè¯æ„å»ºç»“æœ")
            verification = builder.verify_build()
            
            logger.info("\nğŸ‰ å®Œæ•´æ•°æ®åº“å’Œå‘é‡åº“æ„å»ºå®Œæˆ!")
            logger.info("=" * 80)
            logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {builder.stats}")
        
        elif args.action == 'verify':
            verification = builder.verify_build()
            logger.info("âœ… éªŒè¯å®Œæˆ")
        
    except Exception as e:
        logger.error(f"\nâŒ æ“ä½œå¤±è´¥: {e}")
        return 1
    
    finally:
        builder.disconnect()
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
