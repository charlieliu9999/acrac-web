# ACRAC ç³»ç»Ÿæ·±åº¦ä¼˜åŒ–è¯¦ç»†æ–¹æ¡ˆ v2.0

## ğŸ“‹ æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡

åŸºäºé¡¹ç›®ç°çŠ¶åˆ†æï¼Œæˆ‘ä»¬ç¡®å®šäº†ä»¥ä¸‹5ä¸ªå…³é”®ä¼˜åŒ–æ–¹å‘ï¼š

1. **æ¨¡å‹é…ç½®é¡µé¢æ·±åº¦é‡æ„** - æ”¯æŒå¤šæ¨¡å‹æºã€åŠ¨æ€å‘é‡ç»´åº¦ã€å®æ—¶çŠ¶æ€ç›‘æ§
2. **APIæ¶æ„æ¸…ç†ä¸é‡æ„** - ä»78ä¸ªç«¯ç‚¹ä¼˜åŒ–åˆ°30ä¸ªä»¥å†…ï¼Œæå‡21.8%çš„ä½¿ç”¨ç‡
3. **æ¨ç†æµç¨‹æ€§èƒ½ä¼˜åŒ–** - å¹¶è¡Œå¤„ç†ã€å¤šå±‚ç¼“å­˜ã€å“åº”æ—¶é—´<3ç§’
4. **RAGASè¯„æµ‹ç³»ç»Ÿå®Œå–„** - æ‰©å±•è¯„æµ‹æŒ‡æ ‡ã€æ‰¹é‡å¤„ç†ã€å¯è§†åŒ–æŠ¥å‘Š
5. **æ–‡æ¡£ä½“ç³»é‡æ„** - æ¸…ç†å†—ä½™æ–‡æ¡£ã€æ„å»ºæ–°çš„APIæ–‡æ¡£ä½“ç³»

## ğŸ¯ Phase 1: æ¨¡å‹é…ç½®é¡µé¢æ·±åº¦é‡æ„ (ä¼˜å…ˆçº§: æœ€é«˜)

### 1.1 å¤šæ¨¡å‹æºæ”¯æŒæ¶æ„
```typescript
interface ModelProvider {
  id: 'ollama' | 'siliconflow' | 'qwen' | 'openai'
  name: string
  enabled: boolean
  config: {
    base_url: string
    api_key?: string
    embedding_dimension?: number
    max_tokens?: number
  }
  models: {
    embedding: ModelOption[]
    llm: ModelOption[]
    rerank: ModelOption[]
  }
}
```

#### 1.1.1 Ollamaæœ¬åœ°éƒ¨ç½²æ”¯æŒ
- **æœåŠ¡åœ°å€**: http://localhost:11434/v1
- **ç‰¹è‰²åŠŸèƒ½**: æ”¯æŒ2560ç»´Qwen3-4Bæ¨¡å‹
- **å‘é‡ç»´åº¦**: åŠ¨æ€é…ç½® 768/1024/1536/2560
- **æ¨¡å‹åˆ—è¡¨**: qwen3:4b, qwen3:30b, llama3:8b, bge-m3:latest
- **æ•°æ®åº“é€‚é…**: è‡ªåŠ¨è°ƒæ•´pgvectorè¡¨ç»“æ„

#### 1.1.2 SiliconFlowäº‘ç«¯æœåŠ¡
- **APIåœ°å€**: https://api.siliconflow.cn/v1
- **è®¤è¯æ–¹å¼**: Bearer Token
- **æ¨èæ¨¡å‹**: 
  - Embedding: BAAI/bge-m3, BAAI/bge-large-zh-v1.5
  - LLM: Qwen/Qwen2.5-32B-Instruct, Qwen/Qwen2.5-14B-Instruct
  - Rerank: BAAI/bge-reranker-v2-m3

#### 1.1.3 é€šä¹‰åƒé—®DashScope
- **APIåœ°å€**: https://dashscope.aliyuncs.com/compatible-mode/v1
- **è®¤è¯æ–¹å¼**: API Key
- **æ¨¡å‹æ”¯æŒ**: qwen-max, qwen-plus, qwen-turbo, text-embedding-v1/v2

#### 1.1.4 OpenAIå®˜æ–¹æœåŠ¡
- **APIåœ°å€**: https://api.openai.com/v1
- **æ¨¡å‹æ”¯æŒ**: gpt-4o, gpt-4-turbo, text-embedding-3-large/small

### 1.2 æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§

#### 1.2.1 å®æ—¶çŠ¶æ€ç›‘æ§
```typescript
interface SystemStatus {
  api: { status: 'ok' | 'error', version: string }
  db: { status: 'ok' | 'error', vector_count: number }
  embedding: { status: 'ok' | 'error', model: string, dimension: number }
  llm: { status: 'ok' | 'error', model: string }
}
```

#### 1.2.2 åŠ¨æ€å‘é‡ç»´åº¦ç®¡ç†
- **è‡ªåŠ¨æ£€æµ‹**: æ ¹æ®é€‰æ‹©çš„embeddingæ¨¡å‹è‡ªåŠ¨è®¾ç½®ç»´åº¦
- **æ•°æ®åº“è¿ç§»**: æ”¯æŒå‘é‡ç»´åº¦å˜æ›´æ—¶çš„æ•°æ®è¿ç§»
- **å…¼å®¹æ€§æ£€æŸ¥**: ç¡®ä¿æ–°ç»´åº¦ä¸ç°æœ‰æ•°æ®å…¼å®¹

#### 1.2.3 é…ç½®éªŒè¯ä¸æµ‹è¯•
- **è¿æ¥æµ‹è¯•**: å®æ—¶æµ‹è¯•å„æä¾›å•†çš„è¿æ¥çŠ¶æ€
- **æ¨¡å‹éªŒè¯**: éªŒè¯æ¨¡å‹IDçš„æœ‰æ•ˆæ€§
- **æ€§èƒ½åŸºå‡†**: æµ‹è¯•å“åº”æ—¶é—´å’Œå‡†ç¡®æ€§

### 1.3 ç”¨æˆ·ç•Œé¢è®¾è®¡

#### 1.3.1 æä¾›å•†å¡ç‰‡å¸ƒå±€
- **çŠ¶æ€æŒ‡ç¤ºå™¨**: ç»¿è‰²(æ­£å¸¸)/çº¢è‰²(å¼‚å¸¸)/ç°è‰²(ç¦ç”¨)
- **å¿«é€Ÿåˆ‡æ¢**: ä¸€é”®å¯ç”¨/ç¦ç”¨æä¾›å•†
- **é…ç½®é¢æ¿**: æŠ˜å å¼è¯¦ç»†é…ç½®
- **æµ‹è¯•æŒ‰é’®**: å®æ—¶è¿æ¥æµ‹è¯•

#### 1.3.2 æ¨¡å‹é€‰æ‹©å™¨
- **æ™ºèƒ½æ¨è**: æ ¹æ®ä½¿ç”¨åœºæ™¯æ¨èæœ€ä½³æ¨¡å‹
- **æ€§èƒ½æ ‡ç­¾**: æ˜¾ç¤ºæ¨¡å‹çš„æ€§èƒ½ç­‰çº§å’Œæˆæœ¬
- **å…¼å®¹æ€§æç¤º**: æç¤ºå‘é‡ç»´åº¦å…¼å®¹æ€§

### 1.4 æŠ€æœ¯å®ç°è¦ç‚¹

#### 1.4.1 å‰ç«¯ç»„ä»¶æ¶æ„
```
ModelConfigNew.tsx (ä¸»é¡µé¢)
â”œâ”€â”€ SystemStatusCard.tsx (ç³»ç»ŸçŠ¶æ€)
â”œâ”€â”€ ProviderTabs.tsx (æä¾›å•†æ ‡ç­¾é¡µ)
â”‚   â”œâ”€â”€ OllamaConfig.tsx
â”‚   â”œâ”€â”€ SiliconFlowConfig.tsx
â”‚   â”œâ”€â”€ QwenConfig.tsx
â”‚   â””â”€â”€ OpenAIConfig.tsx
â”œâ”€â”€ ModelSelector.tsx (æ¨¡å‹é€‰æ‹©å™¨)
â””â”€â”€ ConfigValidator.tsx (é…ç½®éªŒè¯)
```

#### 1.4.2 åç«¯APIæ‰©å±•
```python
# æ–°å¢APIç«¯ç‚¹
POST /api/v1/admin/models/providers/test
POST /api/v1/admin/models/dimension/migrate
GET  /api/v1/admin/models/compatibility/check
POST /api/v1/admin/models/config/validate
```

## ğŸš€ Phase 2: æ¨ç†æµç¨‹æ·±åº¦ä¼˜åŒ– (ä¼˜å…ˆçº§: é«˜)

### 2.1 å½“å‰æµç¨‹æ€§èƒ½åˆ†æ
```
å½“å‰æµç¨‹ (ä¸²è¡Œå¤„ç†):
ç”¨æˆ·æŸ¥è¯¢ â†’ å‘é‡åŒ–(0.5s) â†’ å‘é‡æœç´¢(1.2s) â†’ é‡æ’åº(0.8s) â†’ LLMæ¨ç†(3.5s) â†’ ç»“æœè¿”å›
æ€»è€—æ—¶: ~6.0s

ç›®æ ‡æµç¨‹ (å¹¶è¡Œä¼˜åŒ–):
ç”¨æˆ·æŸ¥è¯¢ â†’ [å‘é‡åŒ– + ç¼“å­˜æ£€æŸ¥] â†’ [å‘é‡æœç´¢ || é¢„å¤„ç†] â†’ [é‡æ’åº || LLMé¢„çƒ­] â†’ LLMæ¨ç† â†’ ç»“æœè¿”å›
ç›®æ ‡è€—æ—¶: <3.0s (50%æ€§èƒ½æå‡)
```

### 2.2 æ ¸å¿ƒä¼˜åŒ–ç­–ç•¥

#### 2.2.1 å¹¶è¡Œå¤„ç†æ¶æ„
```python
class OptimizedInferenceEngine:
    async def intelligent_recommendation(self, query: str):
        # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡
        tasks = [
            self.vectorize_query(query),           # å‘é‡åŒ–
            self.check_cache(query),               # ç¼“å­˜æ£€æŸ¥
            self.preload_models(),                 # æ¨¡å‹é¢„çƒ­
        ]
        
        vector, cache_result, _ = await asyncio.gather(*tasks)
        
        if cache_result:
            return cache_result
            
        # å¹¶è¡Œæœç´¢å’Œé‡æ’
        search_task = self.vector_search(vector)
        rerank_task = self.prepare_reranker()
        
        search_results = await search_task
        reranked_results = await self.rerank(search_results, await rerank_task)
        
        # LLMæ¨ç†
        final_result = await self.llm_inference(reranked_results)
        
        # å¼‚æ­¥ç¼“å­˜ç»“æœ
        asyncio.create_task(self.cache_result(query, final_result))
        
        return final_result
```

#### 2.2.2 å¤šå±‚ç¼“å­˜ç­–ç•¥
```python
class CacheManager:
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜ (LRU, 1000æ¡)
        self.l2_cache = Redis()  # Redisç¼“å­˜ (1å°æ—¶TTL)
        self.l3_cache = PostgreSQL()  # æ•°æ®åº“ç¼“å­˜ (æ°¸ä¹…)
    
    async def get(self, key: str):
        # L1: å†…å­˜ç¼“å­˜ (æœ€å¿«)
        if key in self.l1_cache:
            return self.l1_cache[key]
            
        # L2: Redisç¼“å­˜ (å¿«)
        result = await self.l2_cache.get(key)
        if result:
            self.l1_cache[key] = result
            return result
            
        # L3: æ•°æ®åº“ç¼“å­˜ (æ…¢ä½†æŒä¹…)
        result = await self.l3_cache.get(key)
        if result:
            await self.l2_cache.setex(key, 3600, result)
            self.l1_cache[key] = result
            return result
            
        return None
```

#### 2.2.3 æ™ºèƒ½æ‰¹å¤„ç†
```python
class BatchProcessor:
    def __init__(self, batch_size=5, timeout=2.0):
        self.batch_size = batch_size
        self.timeout = timeout
        self.pending_requests = []
        
    async def process_request(self, request):
        self.pending_requests.append(request)
        
        if len(self.pending_requests) >= self.batch_size:
            return await self.process_batch()
        else:
            # ç­‰å¾…æ›´å¤šè¯·æ±‚æˆ–è¶…æ—¶
            await asyncio.sleep(self.timeout)
            return await self.process_batch()
    
    async def process_batch(self):
        if not self.pending_requests:
            return []
            
        batch = self.pending_requests[:self.batch_size]
        self.pending_requests = self.pending_requests[self.batch_size:]
        
        # æ‰¹é‡å¤„ç†å‘é‡åŒ–
        vectors = await self.batch_vectorize([r.query for r in batch])
        
        # æ‰¹é‡å‘é‡æœç´¢
        results = await self.batch_vector_search(vectors)
        
        return results
```

#### 2.2.4 é¢„è®¡ç®—ä¸é¢„çƒ­
```python
class PrecomputeManager:
    def __init__(self):
        self.common_queries = [
            "å¤´ç—›çš„å½±åƒæ£€æŸ¥æ¨è",
            "èƒ¸ç—›çš„è¯Šæ–­æ–¹æ¡ˆ",
            "è…¹ç—›çš„æ£€æŸ¥å»ºè®®"
        ]
        
    async def precompute_common_scenarios(self):
        """é¢„è®¡ç®—å¸¸è§åœºæ™¯"""
        for query in self.common_queries:
            result = await self.compute_recommendation(query)
            await self.cache_manager.set(f"precomputed:{query}", result, ttl=86400)
    
    async def warm_up_models(self):
        """æ¨¡å‹é¢„çƒ­"""
        # é¢„çƒ­embeddingæ¨¡å‹
        await self.embedding_service.encode("é¢„çƒ­æ–‡æœ¬")
        
        # é¢„çƒ­LLMæ¨¡å‹
        await self.llm_service.generate("é¢„çƒ­æç¤º", max_tokens=1)
        
        # é¢„çƒ­reranker
        await self.rerank_service.rerank(["æ–‡æ¡£1", "æ–‡æ¡£2"], "æŸ¥è¯¢")
```

### 2.3 æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

#### 2.3.1 å‘é‡ç´¢å¼•ä¼˜åŒ–
```sql
-- åˆ›å»ºHNSWç´¢å¼• (æ›´å¿«çš„è¿‘ä¼¼æœç´¢)
CREATE INDEX CONCURRENTLY idx_scenarios_embedding_hnsw 
ON clinical_scenarios USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ä¼˜åŒ–IVFç´¢å¼•å‚æ•°
SET ivfflat.probes = 50;  -- æé«˜å¬å›ç‡
SET work_mem = '256MB';   -- å¢åŠ å·¥ä½œå†…å­˜
```

#### 2.3.2 æŸ¥è¯¢ä¼˜åŒ–
```python
class OptimizedVectorSearch:
    def __init__(self):
        self.connection_pool = create_pool(min_size=5, max_size=20)
        
    async def search_with_optimization(self, vector, top_k=10):
        async with self.connection_pool.acquire() as conn:
            # ä½¿ç”¨é¢„ç¼–è¯‘è¯­å¥
            query = """
            SELECT id, description_zh, similarity
            FROM (
                SELECT id, description_zh, 
                       1 - (embedding <=> $1) as similarity
                FROM clinical_scenarios
                WHERE 1 - (embedding <=> $1) > $2
                ORDER BY embedding <=> $1
                LIMIT $3
            ) t
            ORDER BY similarity DESC
            """
            
            return await conn.fetch(query, vector, 0.6, top_k)
```

### 2.4 æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜

#### 2.4.1 æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```python
class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'request_count': Counter(),
            'response_time': Histogram(),
            'cache_hit_rate': Gauge(),
            'error_rate': Counter()
        }
    
    def record_request(self, duration, cache_hit=False, error=False):
        self.metrics['request_count'].inc()
        self.metrics['response_time'].observe(duration)
        
        if cache_hit:
            self.metrics['cache_hit_rate'].inc()
        if error:
            self.metrics['error_rate'].inc()
```

#### 2.4.2 è‡ªåŠ¨è°ƒä¼˜
```python
class AutoTuner:
    def __init__(self):
        self.performance_history = []
        
    async def optimize_parameters(self):
        """æ ¹æ®æ€§èƒ½å†å²è‡ªåŠ¨è°ƒä¼˜å‚æ•°"""
        avg_response_time = self.get_avg_response_time()
        
        if avg_response_time > 3.0:
            # å“åº”æ—¶é—´è¿‡é•¿ï¼Œå¢åŠ ç¼“å­˜
            await self.increase_cache_size()
            await self.reduce_search_depth()
        elif avg_response_time < 1.0:
            # å“åº”æ—¶é—´å¾ˆå¿«ï¼Œå¯ä»¥æé«˜è´¨é‡
            await self.increase_search_depth()
            await self.enable_more_reranking()
```

## ğŸ“Š Phase 3: RAGASè¯„æµ‹ç³»ç»Ÿå®Œå–„ (ä¼˜å…ˆçº§: ä¸­)

### 3.1 è¯„æµ‹æŒ‡æ ‡ä½“ç³»æ‰©å±•

#### 3.1.1 æ ¸å¿ƒè¯„æµ‹æŒ‡æ ‡
```python
class RAGASMetrics:
    def __init__(self):
        self.metrics = {
            # åŸæœ‰æŒ‡æ ‡
            'faithfulness': FaithfulnessMetric(),      # å¿ å®åº¦ (0-1)
            'answer_relevancy': AnswerRelevancyMetric(), # ç­”æ¡ˆç›¸å…³æ€§ (0-1)
            'context_precision': ContextPrecisionMetric(), # ä¸Šä¸‹æ–‡ç²¾ç¡®åº¦ (0-1)
            'context_recall': ContextRecallMetric(),    # ä¸Šä¸‹æ–‡å¬å›ç‡ (0-1)
            
            # æ–°å¢æŒ‡æ ‡
            'answer_correctness': AnswerCorrectnessMetric(), # ç­”æ¡ˆæ­£ç¡®æ€§
            'answer_similarity': AnswerSimilarityMetric(),   # ç­”æ¡ˆç›¸ä¼¼æ€§
            'context_relevancy': ContextRelevancyMetric(),   # ä¸Šä¸‹æ–‡ç›¸å…³æ€§
            'response_time': ResponseTimeMetric(),           # å“åº”æ—¶é—´
            'cost_efficiency': CostEfficiencyMetric(),       # æˆæœ¬æ•ˆç‡
        }
    
    async def evaluate_comprehensive(self, 
                                   question: str,
                                   answer: str, 
                                   contexts: List[str],
                                   ground_truth: str = None) -> Dict[str, float]:
        """ç»¼åˆè¯„æµ‹"""
        results = {}
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è¯„æµ‹
        tasks = []
        for name, metric in self.metrics.items():
            task = metric.evaluate(question, answer, contexts, ground_truth)
            tasks.append((name, task))
        
        for name, task in tasks:
            try:
                results[name] = await task
            except Exception as e:
                logger.error(f"è¯„æµ‹æŒ‡æ ‡ {name} å¤±è´¥: {e}")
                results[name] = 0.0
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        results['overall_score'] = self.calculate_overall_score(results)
        
        return results
```

#### 3.1.2 åŒ»ç–—é¢†åŸŸä¸“ç”¨æŒ‡æ ‡
```python
class MedicalRAGASMetrics:
    def __init__(self):
        self.medical_metrics = {
            'clinical_accuracy': ClinicalAccuracyMetric(),     # ä¸´åºŠå‡†ç¡®æ€§
            'safety_compliance': SafetyComplianceMetric(),     # å®‰å…¨åˆè§„æ€§
            'guideline_adherence': GuidelineAdherenceMetric(), # æŒ‡å—éµå¾ªåº¦
            'terminology_accuracy': TerminologyAccuracyMetric(), # æœ¯è¯­å‡†ç¡®æ€§
        }
    
    async def evaluate_medical_response(self, 
                                      clinical_query: str,
                                      recommendation: str,
                                      retrieved_guidelines: List[str]) -> Dict[str, float]:
        """åŒ»ç–—ä¸“ç”¨è¯„æµ‹"""
        results = {}
        
        # æ£€æŸ¥ä¸´åºŠå‡†ç¡®æ€§
        results['clinical_accuracy'] = await self.check_clinical_accuracy(
            clinical_query, recommendation
        )
        
        # æ£€æŸ¥å®‰å…¨åˆè§„æ€§
        results['safety_compliance'] = await self.check_safety_compliance(
            recommendation
        )
        
        # æ£€æŸ¥æŒ‡å—éµå¾ªåº¦
        results['guideline_adherence'] = await self.check_guideline_adherence(
            recommendation, retrieved_guidelines
        )
        
        return results
```

### 3.2 æ‰¹é‡è¯„æµ‹ç³»ç»Ÿ

#### 3.2.1 å¤§è§„æ¨¡æ•°æ®å¤„ç†
```python
class BatchEvaluationEngine:
    def __init__(self, batch_size=50, max_workers=10):
        self.batch_size = batch_size
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        
    async def evaluate_dataset(self, 
                             dataset_path: str,
                             output_path: str,
                             evaluation_config: Dict) -> Dict:
        """æ‰¹é‡è¯„æµ‹æ•°æ®é›†"""
        
        # åŠ è½½æ•°æ®é›†
        dataset = await self.load_dataset(dataset_path)
        total_samples = len(dataset)
        
        # åˆ›å»ºè¿›åº¦è·Ÿè¸ª
        progress = {
            'total': total_samples,
            'completed': 0,
            'failed': 0,
            'start_time': time.time(),
            'results': []
        }
        
        # åˆ†æ‰¹å¤„ç†
        batches = [dataset[i:i+self.batch_size] 
                  for i in range(0, total_samples, self.batch_size)]
        
        for batch_idx, batch in enumerate(batches):
            batch_results = await self.process_batch(batch, evaluation_config)
            
            progress['results'].extend(batch_results)
            progress['completed'] += len(batch_results)
            
            # ä¿å­˜ä¸­é—´ç»“æœ
            if batch_idx % 10 == 0:
                await self.save_intermediate_results(progress, output_path)
            
            # æ›´æ–°è¿›åº¦
            await self.update_progress(progress)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = await self.generate_evaluation_report(progress)
        await self.save_final_report(final_report, output_path)
        
        return final_report
    
    async def process_batch(self, batch: List[Dict], config: Dict) -> List[Dict]:
        """å¤„ç†å•ä¸ªæ‰¹æ¬¡"""
        tasks = []
        
        for sample in batch:
            task = self.evaluate_single_sample(sample, config)
            tasks.append(task)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰¹æ¬¡å†…çš„è¯„æµ‹
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"æ ·æœ¬ {batch[i]['id']} è¯„æµ‹å¤±è´¥: {result}")
                processed_results.append({
                    'id': batch[i]['id'],
                    'status': 'failed',
                    'error': str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results
```

#### 3.2.2 å®æ—¶è¯„æµ‹ç›‘æ§
```python
class RealTimeEvaluationMonitor:
    def __init__(self):
        self.active_evaluations = {}
        self.websocket_connections = set()
        
    async def start_evaluation(self, evaluation_id: str, config: Dict):
        """å¯åŠ¨å®æ—¶è¯„æµ‹"""
        self.active_evaluations[evaluation_id] = {
            'status': 'running',
            'progress': 0,
            'start_time': time.time(),
            'config': config
        }
        
        # é€šçŸ¥æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
        await self.broadcast_status_update(evaluation_id)
    
    async def update_progress(self, evaluation_id: str, progress: float, metrics: Dict):
        """æ›´æ–°è¯„æµ‹è¿›åº¦"""
        if evaluation_id in self.active_evaluations:
            self.active_evaluations[evaluation_id].update({
                'progress': progress,
                'current_metrics': metrics,
                'last_update': time.time()
            })
            
            await self.broadcast_status_update(evaluation_id)
    
    async def broadcast_status_update(self, evaluation_id: str):
        """å¹¿æ’­çŠ¶æ€æ›´æ–°"""
        status = self.active_evaluations.get(evaluation_id)
        if not status:
            return
            
        message = {
            'type': 'evaluation_update',
            'evaluation_id': evaluation_id,
            'status': status
        }
        
        # å‘é€ç»™æ‰€æœ‰WebSocketè¿æ¥
        disconnected = set()
        for ws in self.websocket_connections:
            try:
                await ws.send_json(message)
            except:
                disconnected.add(ws)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        self.websocket_connections -= disconnected
```

### 3.3 å¯¹æ¯”è¯„æµ‹ç³»ç»Ÿ

#### 3.3.1 å¤šæ¨¡å‹å¯¹æ¯”æ¡†æ¶
```python
class ModelComparisonFramework:
    def __init__(self):
        self.models = {}
        self.comparison_metrics = [
            'accuracy', 'response_time', 'cost', 'consistency'
        ]
    
    def register_model(self, name: str, model_config: Dict):
        """æ³¨å†Œå¾…å¯¹æ¯”çš„æ¨¡å‹"""
        self.models[name] = {
            'config': model_config,
            'client': self.create_model_client(model_config)
        }
    
    async def run_comparison(self, 
                           test_dataset: List[Dict],
                           comparison_config: Dict) -> Dict:
        """è¿è¡Œæ¨¡å‹å¯¹æ¯”"""
        
        results = {}
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹è¿è¡Œè¯„æµ‹
        for model_name, model_info in self.models.items():
            logger.info(f"å¼€å§‹è¯„æµ‹æ¨¡å‹: {model_name}")
            
            model_results = await self.evaluate_model(
                model_info['client'],
                test_dataset,
                comparison_config
            )
            
            results[model_name] = model_results
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison_report = await self.generate_comparison_report(results)
        
        return comparison_report
    
    async def generate_comparison_report(self, results: Dict) -> Dict:
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        report = {
            'summary': {},
            'detailed_metrics': {},
            'recommendations': [],
            'visualizations': {}
        }
        
        # è®¡ç®—å„æ¨¡å‹çš„å¹³å‡æŒ‡æ ‡
        for model_name, model_results in results.items():
            avg_metrics = self.calculate_average_metrics(model_results)
            report['summary'][model_name] = avg_metrics
        
        # ç”Ÿæˆæ¨è
        best_model = self.find_best_model(report['summary'])
        report['recommendations'].append({
            'type': 'best_overall',
            'model': best_model,
            'reason': 'ç»¼åˆæ€§èƒ½æœ€ä½³'
        })
        
        # ç”Ÿæˆå¯è§†åŒ–æ•°æ®
        report['visualizations'] = await self.generate_visualization_data(results)
        
        return report
```

### 3.4 å¯è§†åŒ–æŠ¥å‘Šç³»ç»Ÿ

#### 3.4.1 äº¤äº’å¼æŠ¥å‘Šç”Ÿæˆ
```python
class EvaluationReportGenerator:
    def __init__(self):
        self.chart_generators = {
            'metrics_radar': self.generate_radar_chart,
            'time_series': self.generate_time_series_chart,
            'comparison_bar': self.generate_comparison_bar_chart,
            'heatmap': self.generate_heatmap
        }
    
    async def generate_interactive_report(self, 
                                        evaluation_results: Dict,
                                        report_config: Dict) -> str:
        """ç”Ÿæˆäº¤äº’å¼HTMLæŠ¥å‘Š"""
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = {
            'metadata': self.extract_metadata(evaluation_results),
            'summary_metrics': self.calculate_summary_metrics(evaluation_results),
            'detailed_results': evaluation_results,
            'charts': {}
        }
        
        # ç”Ÿæˆå„ç§å›¾è¡¨
        for chart_type, generator in self.chart_generators.items():
            if chart_type in report_config.get('charts', []):
                chart_data = await generator(evaluation_results)
                report_data['charts'][chart_type] = chart_data
        
        # æ¸²æŸ“HTMLæ¨¡æ¿
        template = self.load_report_template()
        html_content = template.render(data=report_data)
        
        return html_content
    
    def generate_radar_chart(self, results: Dict) -> Dict:
        """ç”Ÿæˆé›·è¾¾å›¾æ•°æ®"""
        metrics = ['faithfulness', 'answer_relevancy', 'context_precision', 
                  'context_recall', 'clinical_accuracy']
        
        chart_data = {
            'type': 'radar',
            'data': {
                'labels': metrics,
                'datasets': []
            }
        }
        
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆæ•°æ®é›†
        for model_name, model_results in results.items():
            dataset = {
                'label': model_name,
                'data': [model_results.get(metric, 0) for metric in metrics],
                'borderColor': self.get_model_color(model_name),
                'backgroundColor': self.get_model_color(model_name, alpha=0.2)
            }
            chart_data['data']['datasets'].append(dataset)
        
        return chart_data
```

## ğŸ”§ è¯¦ç»†å®æ–½æ­¥éª¤ä¸æ—¶é—´è§„åˆ’

### Phase 1: æ¨¡å‹é…ç½®é¡µé¢é‡æ„ (Week 1-2, ä¼˜å…ˆçº§: æœ€é«˜)

#### Week 1: å‰ç«¯ç»„ä»¶å¼€å‘
- [x] âœ… åˆ›å»ºModelProviderCardç»„ä»¶
- [ ] ğŸ”„ å¼€å‘SystemStatusCardç»„ä»¶
- [ ] ğŸ“‹ å®ç°ProviderTabsä¸»ç•Œé¢
- [ ] ğŸ¯ æ·»åŠ ModelSelectoræ™ºèƒ½é€‰æ‹©å™¨
- [ ] âš¡ é›†æˆConfigValidatoréªŒè¯å™¨

#### Week 2: åç«¯APIæ‰©å±•
- [ ] ğŸ“¡ æ–°å¢æä¾›å•†æµ‹è¯•API (`/api/v1/admin/models/providers/test`)
- [ ] ğŸ”„ å®ç°å‘é‡ç»´åº¦è¿ç§»API (`/api/v1/admin/models/dimension/migrate`)
- [ ] âœ… æ·»åŠ å…¼å®¹æ€§æ£€æŸ¥API (`/api/v1/admin/models/compatibility/check`)
- [ ] ğŸ›¡ï¸ å¼€å‘é…ç½®éªŒè¯API (`/api/v1/admin/models/config/validate`)
- [ ] ğŸ”§ æ›´æ–°ç°æœ‰é…ç½®APIæ”¯æŒæ–°ç»“æ„

#### å…³é”®äº¤ä»˜ç‰©:
- [ ] æ”¯æŒ4ç§æ¨¡å‹æºçš„é…ç½®ç•Œé¢
- [ ] 2560ç»´Qwen3-4Bæ¨¡å‹æ”¯æŒ
- [ ] å®æ—¶çŠ¶æ€ç›‘æ§é¢æ¿
- [ ] è‡ªåŠ¨é…ç½®éªŒè¯ç³»ç»Ÿ

### Phase 2: APIæ¶æ„æ¸…ç†ä¸é‡æ„ (Week 3-4, ä¼˜å…ˆçº§: é«˜)

#### Week 3: APIä½¿ç”¨æƒ…å†µåˆ†æ
- [ ] ğŸ“Š å®Œæˆ78ä¸ªAPIç«¯ç‚¹çš„è¯¦ç»†ä½¿ç”¨åˆ†æ
- [ ] ğŸ—‘ï¸ è¯†åˆ«61ä¸ªæœªä½¿ç”¨ç«¯ç‚¹ (78.2%)
- [ ] ğŸ“‹ åˆ¶å®šAPIæ¸…ç†è®¡åˆ’
- [ ] ğŸ”„ è®¾è®¡æ–°çš„APIè·¯ç”±ç»“æ„

#### Week 4: APIé‡æ„å®æ–½
- [ ] âŒ ç§»é™¤æœªä½¿ç”¨çš„APIç«¯ç‚¹
- [ ] ğŸ”„ åˆå¹¶åŠŸèƒ½ç›¸ä¼¼çš„ç«¯ç‚¹
- [ ] ğŸ“ é‡æ–°ç»„ç»‡APIè·¯ç”±ç»“æ„
- [ ] ğŸ“š æ›´æ–°APIæ–‡æ¡£å’ŒSwaggerè§„èŒƒ
- [ ] ğŸ§ª æ›´æ–°å‰ç«¯APIè°ƒç”¨

#### ç›®æ ‡æŒ‡æ ‡:
- [ ] APIç«¯ç‚¹æ•°é‡: 78 â†’ 30 (å‡å°‘61.5%)
- [ ] APIä½¿ç”¨ç‡: 21.8% â†’ 90%+
- [ ] ä»£ç ç»´æŠ¤é‡: å‡å°‘30%+

### Phase 3: æ¨ç†æµç¨‹æ€§èƒ½ä¼˜åŒ– (Week 5-6, ä¼˜å…ˆçº§: ä¸­)

#### Week 5: å¹¶è¡Œå¤„ç†å®ç°
- [ ] âš¡ å®ç°OptimizedInferenceEngine
- [ ] ğŸ”„ å¼€å‘å¼‚æ­¥ä»»åŠ¡ç®¡ç†å™¨
- [ ] ğŸ“¦ å®ç°BatchProcessoræ‰¹å¤„ç†
- [ ] ğŸš€ æ·»åŠ æ¨¡å‹é¢„çƒ­æœºåˆ¶

#### Week 6: ç¼“å­˜ä¸æ•°æ®åº“ä¼˜åŒ–
- [ ] ğŸ’¾ å®ç°ä¸‰å±‚ç¼“å­˜æ¶æ„ (L1/L2/L3)
- [ ] ğŸ—ƒï¸ ä¼˜åŒ–pgvectorç´¢å¼•é…ç½®
- [ ] ğŸ“ˆ æ·»åŠ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ
- [ ] ğŸ¯ å®ç°è‡ªåŠ¨è°ƒä¼˜æœºåˆ¶

#### æ€§èƒ½ç›®æ ‡:
- [ ] å“åº”æ—¶é—´: 6.0s â†’ <3.0s (50%æå‡)
- [ ] ç¼“å­˜å‘½ä¸­ç‡: >70%
- [ ] å¹¶å‘å¤„ç†èƒ½åŠ›: 10xæå‡

### Phase 4: RAGASè¯„æµ‹ç³»ç»Ÿå®Œå–„ (Week 7-8, ä¼˜å…ˆçº§: ä¸­)

#### Week 7: è¯„æµ‹æŒ‡æ ‡æ‰©å±•
- [ ] ğŸ“Š å®ç°9ä¸ªæ ¸å¿ƒè¯„æµ‹æŒ‡æ ‡
- [ ] ğŸ¥ æ·»åŠ åŒ»ç–—é¢†åŸŸä¸“ç”¨æŒ‡æ ‡
- [ ] ğŸ“ˆ å¼€å‘ç»¼åˆè¯„åˆ†ç®—æ³•
- [ ] âš¡ å®ç°å¹¶è¡Œè¯„æµ‹å¼•æ“

#### Week 8: æ‰¹é‡å¤„ç†ä¸å¯è§†åŒ–
- [ ] ğŸ“¦ å¼€å‘BatchEvaluationEngine
- [ ] ğŸ“¡ å®ç°å®æ—¶è¯„æµ‹ç›‘æ§
- [ ] ğŸ“Š åˆ›å»ºäº¤äº’å¼æŠ¥å‘Šç”Ÿæˆå™¨
- [ ] ğŸ”„ æ·»åŠ å¤šæ¨¡å‹å¯¹æ¯”æ¡†æ¶

#### åŠŸèƒ½ç›®æ ‡:
- [ ] æ”¯æŒå¤§è§„æ¨¡æ‰¹é‡è¯„æµ‹ (1000+æ ·æœ¬)
- [ ] å®æ—¶è¿›åº¦ç›‘æ§å’ŒWebSocketæ¨é€
- [ ] äº¤äº’å¼HTMLæŠ¥å‘Šç”Ÿæˆ
- [ ] å¤šæ¨¡å‹æ€§èƒ½å¯¹æ¯”åˆ†æ

### Phase 5: æ–‡æ¡£ä½“ç³»é‡æ„ (Week 9-10, ä¼˜å…ˆçº§: ä½)

#### Week 9: æ–‡æ¡£æ¸…ç†ä¸é‡å†™
- [ ] ğŸ—‘ï¸ æ¸…ç†è¿‡æ—¶æ–‡æ¡£ (backup/ç›®å½•)
- [ ] ğŸ“š é‡å†™APIæ–‡æ¡£ (OpenAPI 3.0)
- [ ] ğŸ“– æ›´æ–°éƒ¨ç½²æŒ‡å—
- [ ] ğŸ¯ æ·»åŠ æœ€ä½³å®è·µæŒ‡å—

#### Week 10: æ–‡æ¡£é›†æˆä¸å‘å¸ƒ
- [ ] ğŸ”— é›†æˆæ–‡æ¡£åˆ°é¡¹ç›®ä¸­
- [ ] ğŸŒ éƒ¨ç½²åœ¨çº¿æ–‡æ¡£ç«™ç‚¹
- [ ] ğŸ“ åˆ›å»ºç”¨æˆ·æ‰‹å†Œ
- [ ] ğŸ¥ å½•åˆ¶æ“ä½œæ¼”ç¤ºè§†é¢‘

## ğŸ“ˆ æˆåŠŸæŒ‡æ ‡ä¸éªŒæ”¶æ ‡å‡†

### æŠ€æœ¯æŒ‡æ ‡
- [ ] **æ€§èƒ½æå‡**: æ¨ç†å“åº”æ—¶é—´ < 3ç§’ (å½“å‰6ç§’)
- [ ] **ä»£ç è´¨é‡**: APIç«¯ç‚¹æ•°é‡ < 30ä¸ª (å½“å‰78ä¸ª)
- [ ] **ç”¨æˆ·ä½“éªŒ**: é…ç½®é¡µé¢æ”¯æŒ4ç§æ¨¡å‹æº
- [ ] **ç³»ç»Ÿç¨³å®šæ€§**: é”™è¯¯ç‡ < 5% (ç›®æ ‡é™ä½80%)
- [ ] **è¯„æµ‹å‡†ç¡®æ€§**: RAGASè¯„æµ‹å‡†ç¡®ç‡ > 90%

### ä¸šåŠ¡æŒ‡æ ‡
- [ ] **å¼€å‘æ•ˆç‡**: æ–°åŠŸèƒ½å¼€å‘æ—¶é—´å‡å°‘40%
- [ ] **ç»´æŠ¤æˆæœ¬**: ä»£ç ç»´æŠ¤å·¥ä½œé‡å‡å°‘30%
- [ ] **ç”¨æˆ·æ»¡æ„åº¦**: é…ç½®æ“ä½œä¾¿æ·æ€§æå‡80%
- [ ] **ç³»ç»Ÿå¯ç”¨æ€§**: 99.5%+ æœåŠ¡å¯ç”¨æ€§

### éªŒæ”¶æµ‹è¯•
- [ ] **åŠŸèƒ½æµ‹è¯•**: æ‰€æœ‰æ–°åŠŸèƒ½æ­£å¸¸å·¥ä½œ
- [ ] **æ€§èƒ½æµ‹è¯•**: æ»¡è¶³å“åº”æ—¶é—´è¦æ±‚
- [ ] **å…¼å®¹æ€§æµ‹è¯•**: æ”¯æŒæ‰€æœ‰ç›®æ ‡æ¨¡å‹æº
- [ ] **å‹åŠ›æµ‹è¯•**: æ”¯æŒå¹¶å‘ç”¨æˆ·è®¿é—®
- [ ] **å›å½’æµ‹è¯•**: ç°æœ‰åŠŸèƒ½ä¸å—å½±å“

## ğŸ¯ é£é™©è¯„ä¼°ä¸åº”å¯¹ç­–ç•¥

### é«˜é£é™©é¡¹
1. **å‘é‡ç»´åº¦è¿ç§»**: å¯èƒ½å½±å“ç°æœ‰æ•°æ®
   - åº”å¯¹: å®Œæ•´æ•°æ®å¤‡ä»½ + åˆ†æ­¥è¿ç§» + å›æ»šæ–¹æ¡ˆ

2. **APIé‡æ„å½±å“**: å¯èƒ½ç ´åç°æœ‰é›†æˆ
   - åº”å¯¹: ç‰ˆæœ¬å…¼å®¹ + æ¸è¿›å¼è¿ç§» + å……åˆ†æµ‹è¯•

3. **æ€§èƒ½ä¼˜åŒ–å¤æ‚æ€§**: å¹¶è¡Œå¤„ç†å¯èƒ½å¼•å…¥æ–°bug
   - åº”å¯¹: å°æ­¥å¿«è·‘ + å……åˆ†æµ‹è¯• + ç›‘æ§å‘Šè­¦

### ä¸­é£é™©é¡¹
1. **æ¨¡å‹å…¼å®¹æ€§**: ä¸åŒæä¾›å•†APIå·®å¼‚
   - åº”å¯¹: ç»Ÿä¸€é€‚é…å±‚ + å……åˆ†æµ‹è¯•

2. **ç¼“å­˜ä¸€è‡´æ€§**: å¤šå±‚ç¼“å­˜å¯èƒ½ä¸ä¸€è‡´
   - åº”å¯¹: ç¼“å­˜å¤±æ•ˆç­–ç•¥ + ä¸€è‡´æ€§æ£€æŸ¥

## ğŸ“‹ èµ„æºéœ€æ±‚

### äººåŠ›èµ„æº
- **å‰ç«¯å¼€å‘**: 1äºº Ã— 4å‘¨
- **åç«¯å¼€å‘**: 1äºº Ã— 6å‘¨  
- **æµ‹è¯•å·¥ç¨‹å¸ˆ**: 1äºº Ã— 2å‘¨
- **æ–‡æ¡£å·¥ç¨‹å¸ˆ**: 1äºº Ã— 2å‘¨

### æŠ€æœ¯èµ„æº
- **å¼€å‘ç¯å¢ƒ**: Docker + PostgreSQL + Redis
- **æµ‹è¯•ç¯å¢ƒ**: ç‹¬ç«‹æµ‹è¯•é›†ç¾¤
- **ç›‘æ§å·¥å…·**: Prometheus + Grafana
- **æ–‡æ¡£å·¥å…·**: GitBook æˆ– Docusaurus

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

- **æ€§èƒ½æå‡**: æ¨ç†é€Ÿåº¦æå‡50%+
- **ç”¨æˆ·ä½“éªŒ**: é…ç½®æ›´çµæ´»ï¼Œæ“ä½œæ›´ç®€å•
- **ç»´æŠ¤æˆæœ¬**: ä»£ç é‡å‡å°‘30%+
- **ç³»ç»Ÿç¨³å®šæ€§**: é”™è¯¯ç‡é™ä½80%+

## ğŸ¯ æˆåŠŸæŒ‡æ ‡

- [ ] æ¨¡å‹é…ç½®é¡µé¢æ”¯æŒ4ç§æ¨¡å‹æº
- [ ] APIç«¯ç‚¹æ•°é‡å‡å°‘åˆ°30ä¸ªä»¥å†…
- [ ] æ¨ç†å“åº”æ—¶é—´ < 3ç§’
- [ ] RAGASè¯„æµ‹å‡†ç¡®ç‡ > 90%
- [ ] æ–‡æ¡£è¦†ç›–ç‡ > 95%